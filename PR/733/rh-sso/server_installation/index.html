<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" class="chrometwo"><head><title>Server Installation and Configuration Guide</title><link rel="stylesheet" type="text/css" href="Common_Content/css/default.css"/><meta name="generator" content="publican v4.3.4"/><meta name="description" content="This guide consists of information to install and configure Red Hat Single Sign-On Continuous Delivery 6"/><link rel="next" href="#guide_overview" title="Chapter 1. Guide Overview"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><script type="text/javascript" src="Common_Content/scripts/jquery-1.7.1.min.js"> </script><script type="text/javascript" src="Common_Content/scripts/utils.js"> </script><script type="text/javascript" src="Common_Content/scripts/highlight.js/highlight.pack.js"> </script></head><body><div id="chrometwo"><div id="main"><div xml:lang="en-US" class="book" id="idm140154421885440"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Single Sign-On Continuous Delivery</span> <span class="productnumber">6</span></div><div><h1 class="title">Server Installation and Configuration Guide</h1></div><div><h2 class="subtitle">For Use with Red Hat Single Sign-On Continuous Delivery 6</h2></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat Customer Content Services</span></div></div><div><a href="#idm140154420637184">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				This guide consists of information to install and configure Red Hat Single Sign-On Continuous Delivery 6
			</div></div></div></div><hr/></div><div class="toc"><ul class="toc"><li><span class="chapter"><a href="#guide_overview">1. Guide Overview</a></span><ul><li><span class="section"><a href="#recommended_additional_external_documentation">1.1. Recommended Additional External Documentation</a></span></li></ul></li><li><span class="chapter"><a href="#installation">2. Installation</a></span><ul><li><span class="section"><a href="#system_requirements">2.1. System Requirements</a></span></li><li><span class="section"><a href="#installing_rh_sso_from_a_zip_file">2.2. Installing RH-SSO from a ZIP File</a></span></li><li><span class="section"><a href="#installing_rpm">2.3. Installing RH-SSO from an RPM</a></span><ul><li><span class="section"><a href="#subscribing_EAP_repo">2.3.1. Subscribing to the JBoss EAP 7.2 Repository</a></span></li><li><span class="section"><a href="#subscribing_to_the_rh_sso_6_repository_and_installing_rh_sso_6">2.3.2. Subscribing to the RH-SSO 6 Repository and Installing RH-SSO 6</a></span></li></ul></li><li><span class="section"><a href="#distribution_directory_structure">2.4. Distribution Directory Structure</a></span></li></ul></li><li><span class="chapter"><a href="#operating-mode">3. Choosing an Operating Mode</a></span><ul><li><span class="section"><a href="#standalone-mode">3.1. Standalone Mode</a></span><ul><li><span class="section"><a href="#standalone_boot_script">3.1.1. Standalone Boot Script</a></span></li><li><span class="section"><a href="#standalone_configuration">3.1.2. Standalone Configuration</a></span></li></ul></li><li><span class="section"><a href="#standalone-ha-mode">3.2. Standalone Clustered Mode</a></span><ul><li><span class="section"><a href="#standalone_clustered_configuration">3.2.1. Standalone Clustered Configuration</a></span></li><li><span class="section"><a href="#standalone_clustered_boot_script">3.2.2. Standalone Clustered Boot Script</a></span></li></ul></li><li><span class="section"><a href="#domain-mode">3.3. Domain Clustered Mode</a></span><ul><li><span class="section"><a href="#domain_configuration">3.3.1. Domain Configuration</a></span></li><li><span class="section"><a href="#host_controller_configuration">3.3.2. Host Controller Configuration</a></span></li><li><span class="section"><a href="#server_instance_working_directories">3.3.3. Server Instance Working Directories</a></span></li><li><span class="section"><a href="#domain_boot_script">3.3.4. Domain Boot Script</a></span></li><li><span class="section"><a href="#clustered-domain-example">3.3.5. Clustered Domain Example</a></span></li></ul></li><li><span class="section"><a href="#crossdc-mode">3.4. Cross-Datacenter Replication Mode</a></span><ul><li><span class="section"><a href="#prerequisites">3.4.1. Prerequisites</a></span></li><li><span class="section"><a href="#technicaldetails">3.4.2. Technical details</a></span></li><li><span class="section"><a href="#requestprocessing">3.4.3. Request processing</a></span></li><li><span class="section"><a href="#modes">3.4.4. Modes</a></span></li><li><span class="section"><a href="#database">3.4.5. Database</a></span></li><li><span class="section"><a href="#cache">3.4.6. Infinispan caches</a></span></li><li><span class="section"><a href="#communication">3.4.7. Communication details</a></span></li><li><span class="section"><a href="#setup">3.4.8. Basic setup</a></span></li><li><span class="section"><a href="#administration">3.4.9. Administration of Cross DC deployment</a></span></li><li><span class="section"><a href="#onoffline">3.4.10. Bringing sites offline and online</a></span></li><li><span class="section"><a href="#statetransfer">3.4.11. State transfer</a></span></li><li><span class="section"><a href="#clearcache">3.4.12. Clear caches</a></span></li><li><span class="section"><a href="#tuningcache">3.4.13. Tuning the JDG cache configuration</a></span></li><li><span class="section"><a href="#backups">3.4.14. SYNC or ASYNC backups</a></span></li><li><span class="section"><a href="#troubleshooting">3.4.15. Troubleshooting</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#manage_subsystem_configuration">4. Manage Subsystem Configuration</a></span><ul><li><span class="section"><a href="#config_spi_providers">4.1. Configure SPI Providers</a></span></li><li><span class="section"><a href="#start_cli">4.2. Start the JBoss EAP CLI</a></span></li><li><span class="section"><a href="#cli_embedded_mode">4.3. CLI Embedded Mode</a></span></li><li><span class="section"><a href="#cli_gui_mode">4.4. CLI GUI Mode</a></span></li><li><span class="section"><a href="#cli_scripting">4.5. CLI Scripting</a></span></li><li><span class="section"><a href="#cli_recipes">4.6. CLI Recipes</a></span><ul><li><span class="section"><a href="#change_the_web_context_of_the_server">4.6.1. Change the web context of the server</a></span></li><li><span class="section"><a href="#set_the_global_default_theme">4.6.2. Set the global default theme</a></span></li><li><span class="section"><a href="#add_a_new_spi_and_a_provider">4.6.3. Add a new SPI and a provider</a></span></li><li><span class="section"><a href="#disable_a_provider">4.6.4. Disable a provider</a></span></li><li><span class="section"><a href="#change_the_default_provider_for_an_spi">4.6.5. Change the default provider for an SPI</a></span></li><li><span class="section"><a href="#configure_the_dblock_spi">4.6.6. Configure the dblock SPI</a></span></li><li><span class="section"><a href="#add_or_change_a_single_property_value_for_a_provider">4.6.7. Add or change a single property value for a provider</a></span></li><li><span class="section"><a href="#remove_a_single_property_from_a_provider">4.6.8. Remove a single property from a provider</a></span></li><li><span class="section"><a href="#set_values_on_a_provider_property_of_type_literal_list_literal">4.6.9. Set values on a provider property of type <code class="literal">List</code></a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#profiles">5. Profiles</a></span></li><li><span class="chapter"><a href="#database-1">6. Relational Database Setup</a></span><ul><li><span class="section"><a href="#rdbms-setup-checklist">6.1. RDBMS Setup Checklist</a></span></li><li><span class="section"><a href="#package_the_jdbc_driver">6.2. Package the JDBC Driver</a></span></li><li><span class="section"><a href="#declare_and_load_jdbc_driver">6.3. Declare and Load JDBC Driver</a></span></li><li><span class="section"><a href="#modify_the_red_hat_single_sign_on_datasource">6.4. Modify the Red Hat Single Sign-On Datasource</a></span></li><li><span class="section"><a href="#database_configuration">6.5. Database Configuration</a></span></li><li><span class="section"><a href="#unicode_considerations_for_databases">6.6. Unicode Considerations for Databases</a></span><ul><li><span class="section"><a href="#oracle_database">6.6.1. Oracle Database</a></span></li><li><span class="section"><a href="#microsoft_sql_server_database">6.6.2. Microsoft SQL Server Database</a></span></li><li><span class="section"><a href="#mysql_database">6.6.3. MySQL Database</a></span></li><li><span class="section"><a href="#postgresql_database">6.6.4. PostgreSQL Database</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#network">7. Network Setup</a></span><ul><li><span class="section"><a href="#bind-address">7.1. Bind Addresses</a></span></li><li><span class="section"><a href="#ports">7.2. Socket Port Bindings</a></span></li><li><span class="section"><a href="#setting_up_https_ssl">7.3. Setting up HTTPS/SSL</a></span><ul><li><span class="section"><a href="#enabling_ssl_https_for_the_red_hat_single_sign_on_server">7.3.1. Enabling SSL/HTTPS for the Red Hat Single Sign-On Server</a></span></li></ul></li><li><span class="section"><a href="#outgoing_http_requests">7.4. Outgoing HTTP Requests</a></span><ul><li><span class="section"><a href="#proxymappings">7.4.1. Proxy Mappings for Outgoing HTTP Requests</a></span></li><li><span class="section"><a href="#truststore">7.4.2. Outgoing HTTPS Request Truststore</a></span></li></ul></li></ul></li><li><span class="chapter"><a href="#clustering">8. Clustering</a></span><ul><li><span class="section"><a href="#recommended_network_architecture">8.1. Recommended Network Architecture</a></span></li><li><span class="section"><a href="#clustering_example">8.2. Clustering Example</a></span></li><li><span class="section"><a href="#setting-up-a-load-balancer-or-proxy">8.3. Setting Up a Load Balancer or Proxy</a></span><ul><li><span class="section"><a href="#identifying_client_ip_addresses">8.3.1. Identifying Client IP Addresses</a></span></li><li><span class="section"><a href="#enable_https_ssl_with_a_reverse_proxy">8.3.2. Enable HTTPS/SSL with a Reverse Proxy</a></span></li><li><span class="section"><a href="#verify_configuration">8.3.3. Verify Configuration</a></span></li><li><span class="section"><a href="#using_the_built_in_load_balancer">8.3.4. Using the Built-In Load Balancer</a></span></li><li><span class="section"><a href="#configuring_other_load_balancers">8.3.5. Configuring Other Load Balancers</a></span></li></ul></li><li><span class="section"><a href="#sticky-sessions">8.4. Sticky sessions</a></span><ul><li><span class="section"><a href="#disable_adding_the_route">8.4.1. Disable adding the route</a></span></li></ul></li><li><span class="section"><a href="#multicast_network_setup">8.5. Multicast Network Setup</a></span></li><li><span class="section"><a href="#securing_cluster_communication">8.6. Securing Cluster Communication</a></span></li><li><span class="section"><a href="#clustering_db_lock">8.7. Serialized Cluster Startup</a></span></li><li><span class="section"><a href="#booting_the_cluster">8.8. Booting the Cluster</a></span></li><li><span class="section"><a href="#troubleshooting-1">8.9. Troubleshooting</a></span></li></ul></li><li><span class="chapter"><a href="#cache-configuration">9. Server Cache Configuration</a></span><ul><li><span class="section"><a href="#eviction">9.1. Eviction and Expiration</a></span></li><li><span class="section"><a href="#replication">9.2. Replication and Failover</a></span></li><li><span class="section"><a href="#disabling_caching">9.3. Disabling Caching</a></span></li><li><span class="section"><a href="#clearing_caches_at_runtime">9.4. Clearing Caches at Runtime</a></span></li></ul></li></ul></div><section class="chapter" id="guide_overview"><div class="titlepage"><div><div><h1 class="title">Chapter 1. Guide Overview</h1></div></div></div><p>
			The purpose of this guide is to walk through the steps that need to be completed prior to booting up the Red Hat Single Sign-On server for the first time. If you just want to test drive Red Hat Single Sign-On, it pretty much runs out of the box with its own embedded and local-only database. For actual deployments that are going to be run in production you’ll need to decide how you want to manage server configuration at runtime (standalone or domain mode), configure a shared database for Red Hat Single Sign-On storage, set up encryption and HTTPS, and finally set up Red Hat Single Sign-On to run in a cluster. This guide walks through each and every aspect of any pre-boot decisions and setup you must do prior to deploying the server.
		</p><p>
			One thing to particularly note is that Red Hat Single Sign-On is derived from the JBoss EAP Application Server. Many aspects of configuring Red Hat Single Sign-On revolve around JBoss EAP configuration elements. Often this guide will direct you to documentation outside of the manual if you want to dive into more detail.
		</p><section class="section" id="recommended_additional_external_documentation"><div class="titlepage"><div><div><h2 class="title">1.1. Recommended Additional External Documentation</h2></div></div></div><p>
				Red Hat Single Sign-On is built on top of the JBoss EAP application server and it’s sub-projects like Infinispan (for caching) and Hibernate (for persistence). This guide only covers basics for infrastructure-level configuration. It is highly recommended that you peruse the documentation for JBoss EAP and its sub projects. Here is the link to the documentation:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a>
					</li></ul></div></section></section><section class="chapter" id="installation"><div class="titlepage"><div><div><h1 class="title">Chapter 2. Installation</h1></div></div></div><p>
			You can install Red Hat Single Sign-On by downloading a ZIP file and unzipping it, or by using an RPM. This chapter reviews system requirements as well as the directory structure.
		</p><section class="section" id="system_requirements"><div class="titlepage"><div><div><h2 class="title">2.1. System Requirements</h2></div></div></div><p>
				These are the requirements to run the Red Hat Single Sign-On authentication server:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Can run on any operating system that runs Java
					</li><li class="listitem">
						Java 8 JDK
					</li><li class="listitem">
						zip or gzip and tar
					</li><li class="listitem">
						At least 512M of RAM
					</li><li class="listitem">
						At least 1G of diskspace
					</li><li class="listitem">
						A shared external database like PostgreSQL, MySQL, Oracle, etc. Red Hat Single Sign-On requires an external shared database if you want to run in a cluster. Please see the <a class="link" href="#database-1" title="Chapter 6. Relational Database Setup">database configuration</a> section of this guide for more information.
					</li><li class="listitem">
						Network multicast support on your machine if you want to run in a cluster. Red Hat Single Sign-On can be clustered without multicast, but this requires a bunch of configuration changes. Please see the <a class="link" href="#clustering" title="Chapter 8. Clustering">clustering</a> section of this guide for more information.
					</li><li class="listitem">
						On Linux, it is recommended to use <code class="literal">/dev/urandom</code> as a source of random data to prevent Red Hat Single Sign-On hanging due to lack of available entropy, unless <code class="literal">/dev/random</code> usage is mandated by your security policy. To achieve that on Oracle JDK 8 and OpenJDK 8, set the <code class="literal">java.security.egd</code> system property on startup to <code class="literal">file:/dev/urandom</code>.
					</li></ul></div></section><section class="section" id="installing_rh_sso_from_a_zip_file"><div class="titlepage"><div><div><h2 class="title">2.2. Installing RH-SSO from a ZIP File</h2></div></div></div><p>
				The Red Hat Single Sign-On Server is contained in one distribution file: rh-sso-6.zip.gz.
			</p><p>
				The rh-sso-6.zip.gz archive is the server-only distribution. It contains only the scripts and binaries to run Red Hat Single Sign-On Server.
			</p><p>
				To unpack these files, run the <code class="literal">unzip</code> or <code class="literal">gunzip</code> utility.
			</p></section><section class="section" id="installing_rpm"><div class="titlepage"><div><div><h2 class="title">2.3. Installing RH-SSO from an RPM</h2></div></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					With Red Hat Enterprise Linux 7 and 8, the term channel was replaced with the term repository. In these instructions only the term repository is used.
				</p></div></div><p>
				You must subscribe to both the JBoss EAP 7.2 and RH-SSO 6 repositories before you can install RH-SSO from an RPM.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					You cannot continue to receive upgrades to EAP RPMs but stop receiving updates for RH-SSO.
				</p></div></div><section class="section" id="subscribing_EAP_repo"><div class="titlepage"><div><div><h3 class="title">2.3.1. Subscribing to the JBoss EAP 7.2 Repository</h3></div></div></div><div class="orderedlist"><p class="title"><strong>Prerequisites</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Ensure that your Red Hat Enterprise Linux system is registered to your account using Red Hat Subscription Manager. For more information see the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_subscription_management/1/html-single/quick_registration_for_rhel/index">Red Hat Subscription Management documentation</a>.
						</li><li class="listitem">
							If you are already subscribed to another JBoss EAP repository, you must unsubscribe from that repository first.
						</li></ol></div><p>
					For Red Hat Enterprise Linux 6, 7: Using Red Hat Subscription Manager, subscribe to the JBoss EAP 7.2 repository using the following command. Replace &lt;RHEL_VERSION&gt; with either 6 or 7 depending on your Red Hat Enterprise Linux version.
				</p><pre class="programlisting language-bash">subscription-manager repos --enable=jb-eap-7.2-for-rhel-&lt;RHEL_VERSION&gt;-server-rpms --enable=rhel-&lt;RHEL_VERSION&gt;-server-rpms</pre><p>
					For Red Hat Enterprise Linux 8: Using Red Hat Subscription Manager, subscribe to the JBoss EAP 7.2 repository using the following command:
				</p><pre class="programlisting language-bash">subscription-manager repos --enable=jb-eap-7.2-for-rhel-8-x86_64-rpms --enable=rhel-8-for-x86_64-baseos-rpms --enable=rhel-8-for-x86_64-appstream-rpms</pre></section><section class="section" id="subscribing_to_the_rh_sso_6_repository_and_installing_rh_sso_6"><div class="titlepage"><div><div><h3 class="title">2.3.2. Subscribing to the RH-SSO 6 Repository and Installing RH-SSO 6</h3></div></div></div><div class="orderedlist"><p class="title"><strong>Prerequisites</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Ensure that your Red Hat Enterprise Linux system is registered to your account using Red Hat Subscription Manager. For more information see the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_subscription_management/1/html-single/quick_registration_for_rhel/index">Red Hat Subscription Management documentation</a>.
						</li><li class="listitem">
							Ensure that you have already subscribed to the JBoss EAP 7.2 repository. For more information see <a class="link" href="#subscribing_EAP_repo" title="2.3.1. Subscribing to the JBoss EAP 7.2 Repository">Subscribing to the JBoss EAP 7.2 repository</a>.
						</li></ol></div><p>
					To subscribe to the RH-SSO 6 repository and install RH-SSO 6, complete the following steps:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							For Red Hat Enterprise Linux 6, 7: Using Red Hat Subscription Manager, subscribe to the RH-SSO 6 repository using the following command. Replace &lt;RHEL_VERSION&gt; with either 6 or 7 depending on your Red Hat Enterprise Linux version.
						</p><pre class="programlisting language-bash">subscription-manager repos --enable=rh-sso-6-for-rhel-&lt;RHEL-VERSION&gt;-server-rpms</pre></li><li class="listitem"><p class="simpara">
							For Red Hat Enterprise Linux 8: Using Red Hat Subscription Manager, subscribe to the RH-SSO 6 repository using the following command:
						</p><pre class="programlisting language-bash">subscription-manager repos --enable=rh-sso-6-for-rhel-8-x86_64-rpms</pre></li><li class="listitem"><p class="simpara">
							For Red Hat Enterprise Linux 6, 7: Install RH-SSO from your subscribed RH-SSO 6 repository using the following command:
						</p><pre class="literallayout">yum groupinstall rh-sso7</pre></li><li class="listitem"><p class="simpara">
							For Red Hat Enterprise Linux 8: Install RH-SSO from your subscribed RH-SSO 6 repository using the following command:
						</p><pre class="literallayout">dnf groupinstall rh-sso7</pre></li></ol></div><p>
					Your installation is complete. The default RH-SSO_HOME path for the RPM installation is /opt/rh/rh-sso7/root/usr/share/keycloak.
				</p></section></section><section class="section" id="distribution_directory_structure"><div class="titlepage"><div><div><h2 class="title">2.4. Distribution Directory Structure</h2></div></div></div><p>
				This chapter walks you through the directory structure of the server distribution.
			</p><div class="formalpara"><p class="title"><strong>distribution directory structure</strong></p><p>
					<span class="inlinemediaobject"><img src="images/rhsso-images/files.png" alt="distribution"/></span>
				</p></div><p>
				Let’s examine the purpose of some of the directories:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="emphasis"><em>bin/</em></span></span></dt><dd>
							This contains various scripts to either boot the server or perform some other management action on the server.
						</dd><dt><span class="term"><span class="emphasis"><em>domain/</em></span></span></dt><dd>
							This contains configuration files and working directory when running Red Hat Single Sign-On in <a class="link" href="#domain-mode" title="3.3. Domain Clustered Mode">domain mode</a>.
						</dd><dt><span class="term"><span class="emphasis"><em>modules/</em></span></span></dt><dd>
							These are all the Java libraries used by the server.
						</dd><dt><span class="term"><span class="emphasis"><em>standalone/</em></span></span></dt><dd>
							This contains configuration files and working directory when running Red Hat Single Sign-On in <a class="link" href="#standalone-mode" title="3.1. Standalone Mode">standalone mode</a>.
						</dd><dt><span class="term"><span class="emphasis"><em>themes/</em></span></span></dt><dd>
							This directory contains all the html, style sheets, JavaScript files, and images used to display any UI screen displayed by the server. Here you can modify an existing theme or create your own. See the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_developer_guide/">Server Developer Guide</a> for more information on this.
						</dd></dl></div></section></section><section class="chapter" id="operating-mode"><div class="titlepage"><div><div><h1 class="title">Chapter 3. Choosing an Operating Mode</h1></div></div></div><p>
			Before deploying Red Hat Single Sign-On in a production environment you need to decide which type of operating mode you are going to use. Will you run Red Hat Single Sign-On within a cluster? Do you want a centralized way to manage your server configurations? Your choice of operating mode effects how you configure databases, configure caching and even how you boot the server.
		</p><div class="admonition tip"><div class="admonition_header">Tip</div><div><p>
			The Red Hat Single Sign-On is built on top of the JBoss EAP Application Server. This guide will only go over the basics for deployment within a specific mode. If you want specific information on this, a better place to go would be the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a>.
		</p></div></div><section class="section" id="standalone-mode"><div class="titlepage"><div><div><h2 class="title">3.1. Standalone Mode</h2></div></div></div><p>
				Standalone operating mode is only useful when you want to run one, and only one Red Hat Single Sign-On server instance. It is not usable for clustered deployments and all caches are non-distributed and local-only. It is not recommended that you use standalone mode in production as you will have a single point of failure. If your standalone mode server goes down, users will not be able to log in. This mode is really only useful to test drive and play with the features of Red Hat Single Sign-On
			</p><section class="section" id="standalone_boot_script"><div class="titlepage"><div><div><h3 class="title">3.1.1. Standalone Boot Script</h3></div></div></div><p>
					When running the server in standalone mode, there is a specific script you need to run to boot the server depending on your operating system. These scripts live in the <span class="emphasis"><em>bin/</em></span> directory of the server distribution.
				</p><div class="formalpara"><p class="title"><strong>Standalone Boot Scripts</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/standalone-boot-files.png" alt="standalone boot files"/></span>
					</p></div><p>
					To boot the server:
				</p><div class="formalpara"><p class="title"><strong>Linux/Unix</strong></p><p>
						
<pre class="screen">$ .../bin/standalone.sh</pre>
					</p></div><div class="formalpara"><p class="title"><strong>Windows</strong></p><p>
						
<pre class="screen">&gt; ...\bin\standalone.bat</pre>
					</p></div></section><section class="section" id="standalone_configuration"><div class="titlepage"><div><div><h3 class="title">3.1.2. Standalone Configuration</h3></div></div></div><p>
					The bulk of this guide walks you through how to configure infrastructure level aspects of Red Hat Single Sign-On. These aspects are configured in a configuration file that is specific to the application server that Red Hat Single Sign-On is a derivative of. In the standalone operation mode, this file lives in <span class="emphasis"><em>…​/standalone/configuration/standalone.xml</em></span>. This file is also used to configure non-infrastructure level things that are specific to Red Hat Single Sign-On components.
				</p><div class="formalpara"><p class="title"><strong>Standalone Config File</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/standalone-config-file.png" alt="standalone config file"/></span>
					</p></div><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						Any changes you make to this file while the server is running will not take effect and may even be overwritten by the server. Instead use the command line scripting or the web console of JBoss EAP. See the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a> for more information.
					</p></div></div></section></section><section class="section" id="standalone-ha-mode"><div class="titlepage"><div><div><h2 class="title">3.2. Standalone Clustered Mode</h2></div></div></div><p>
				Standalone clustered operation mode is for when you want to run Red Hat Single Sign-On within a cluster. This mode requires that you have a copy of the Red Hat Single Sign-On distribution on each machine you want to run a server instance. This mode can be very easy to deploy initially, but can become quite cumbersome. To make a configuration change you’ll have to modify each distribution on each machine. For a large cluster this can become time consuming and error prone.
			</p><section class="section" id="standalone_clustered_configuration"><div class="titlepage"><div><div><h3 class="title">3.2.1. Standalone Clustered Configuration</h3></div></div></div><p>
					The distribution has a mostly pre-configured app server configuration file for running within a cluster. It has all the specific infrastructure settings for networking, databases, caches, and discovery. This file resides in <span class="emphasis"><em>…​/standalone/configuration/standalone-ha.xml</em></span>. There’s a few things missing from this configuration. You can’t run Red Hat Single Sign-On in a cluster without configuring a shared database connection. You also need to deploy some type of load balancer in front of the cluster. The <a class="link" href="#clustering" title="Chapter 8. Clustering">clustering</a> and <a class="link" href="#database-1" title="Chapter 6. Relational Database Setup">database</a> sections of this guide walk you though these things.
				</p><div class="formalpara"><p class="title"><strong>Standalone HA Config</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/standalone-ha-config-file.png" alt="standalone ha config file"/></span>
					</p></div><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						Any changes you make to this file while the server is running will not take effect and may even be overwritten by the server. Instead use the command line scripting or the web console of JBoss EAP. See the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a> for more information.
					</p></div></div></section><section class="section" id="standalone_clustered_boot_script"><div class="titlepage"><div><div><h3 class="title">3.2.2. Standalone Clustered Boot Script</h3></div></div></div><p>
					You use the same boot scripts to start Red Hat Single Sign-On as you do in standalone mode. The difference is that you pass in an additional flag to point to the HA config file.
				</p><div class="formalpara"><p class="title"><strong>Standalone Clustered Boot Scripts</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/standalone-boot-files.png" alt="standalone boot files"/></span>
					</p></div><p>
					To boot the server:
				</p><div class="formalpara"><p class="title"><strong>Linux/Unix</strong></p><p>
						
<pre class="screen">$ .../bin/standalone.sh --server-config=standalone-ha.xml</pre>
					</p></div><div class="formalpara"><p class="title"><strong>Windows</strong></p><p>
						
<pre class="screen">&gt; ...\bin\standalone.bat --server-config=standalone-ha.xml</pre>
					</p></div></section></section><section class="section" id="domain-mode"><div class="titlepage"><div><div><h2 class="title">3.3. Domain Clustered Mode</h2></div></div></div><p>
				Domain mode is a way to centrally manage and publish the configuration for your servers.
			</p><p>
				Running a cluster in standard mode can quickly become aggravating as the cluster grows in size. Every time you need to make a configuration change, you have perform it on each node in the cluster. Domain mode solves this problem by providing a central place to store and publish configuration. It can be quite complex to set up, but it is worth it in the end. This capability is built into the JBoss EAP Application Server which Red Hat Single Sign-On derives from.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					The guide will go over the very basics of domain mode. Detailed steps on how to set up domain mode in a cluster should be obtained from the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a>.
				</p></div></div><p>
				Here are some of the basic concepts of running in domain mode.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">domain controller</span></dt><dd>
							The domain controller is a process that is responsible for storing, managing, and publishing the general configuration for each node in the cluster. This process is the central point from which nodes in a cluster obtain their configuration.
						</dd><dt><span class="term">host controller</span></dt><dd>
							The host controller is responsible for managing server instances on a specific machine. You configure it to run one or more server instances. The domain controller can also interact with the host controllers on each machine to manage the cluster. To reduce the number of running process, a domain controller also acts as a host controller on the machine it runs on.
						</dd><dt><span class="term">domain profile</span></dt><dd>
							A domain profile is a named set of configuration that can be used by a server to boot from. A domain controller can define multiple domain profiles that are consumed by different servers.
						</dd><dt><span class="term">server group</span></dt><dd>
							A server group is a collection of servers. They are managed and configured as one. You can assign a domain profile to a server group and every service in that group will use that domain profile as their configuration.
						</dd></dl></div><p>
				In domain mode, a domain controller is started on a master node. The configuration for the cluster resides in the domain controller. Next a host controller is started on each machine in the cluster. Each host controller deployment configuration specifies how many Red Hat Single Sign-On server instances will be started on that machine. When the host controller boots up, it starts as many Red Hat Single Sign-On server instances as it was configured to do. These server instances pull their configuration from the domain controller.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					In some environments, such as Microsoft Azure, the domain mode is not applicable. Please consult the JBoss EAP documentation.
				</p></div></div><section class="section" id="domain_configuration"><div class="titlepage"><div><div><h3 class="title">3.3.1. Domain Configuration</h3></div></div></div><p>
					Various other chapters in this guide walk you through configuring various aspects like databases, HTTP network connections, caches, and other infrastructure related things. While standalone mode uses the <span class="emphasis"><em>standalone.xml</em></span> file to configure these things, domain mode uses the <span class="emphasis"><em>…​/domain/configuration/domain.xml</em></span> configuration file. This is where the domain profile and server group for the Red Hat Single Sign-On server are defined.
				</p><div class="formalpara"><p class="title"><strong>domain.xml</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/domain-file.png" alt="domain file"/></span>
					</p></div><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						Any changes you make to this file while the domain controller is running will not take effect and may even be overwritten by the server. Instead use the command line scripting or the web console of JBoss EAP. See the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a> for more information.
					</p></div></div><p>
					Let’s look at some aspects of this <span class="emphasis"><em>domain.xml</em></span> file. The <code class="literal">auth-server-standalone</code> and <code class="literal">auth-server-clustered</code> <code class="literal">profile</code> XML blocks are where you are going to make the bulk of your configuration decisions. You’ll be configuring things here like network connections, caches, and database connections.
				</p><div class="formalpara"><p class="title"><strong>auth-server profile</strong></p><p>
						
<pre class="programlisting language-xml">    &lt;profiles&gt;
        &lt;profile name="auth-server-standalone"&gt;
            ...
        &lt;/profile&gt;
        &lt;profile name="auth-server-clustered"&gt;
            ...
        &lt;/profile&gt;</pre>
					</p></div><p>
					The <code class="literal">auth-server-standalone</code> profile is a non-clustered setup. The <code class="literal">auth-server-clustered</code> profile is the clustered setup.
				</p><p>
					If you scroll down further, you’ll see various <code class="literal">socket-binding-groups</code> defined.
				</p><div class="formalpara"><p class="title"><strong>socket-binding-groups</strong></p><p>
						
<pre class="programlisting language-xml">    &lt;socket-binding-groups&gt;
        &lt;socket-binding-group name="standard-sockets" default-interface="public"&gt;
           ...
        &lt;/socket-binding-group&gt;
        &lt;socket-binding-group name="ha-sockets" default-interface="public"&gt;
           ...
        &lt;/socket-binding-group&gt;
        &lt;!-- load-balancer-sockets should be removed in production systems and replaced with a better software or hardware based one --&gt;
        &lt;socket-binding-group name="load-balancer-sockets" default-interface="public"&gt;
           ...
        &lt;/socket-binding-group&gt;
    &lt;/socket-binding-groups&gt;</pre>
					</p></div><p>
					This config defines the default port mappings for various connectors that are opened with each Red Hat Single Sign-On server instance. Any value that contains <code class="literal">${…​}</code> is a value that can be overridden on the command line with the <code class="literal">-D</code> switch, i.e.
				</p><pre class="screen">$ domain.sh -Djboss.http.port=80</pre><p>
					The definition of the server group for Red Hat Single Sign-On resides in the <code class="literal">server-groups</code> XML block. It specifies the domain profile that is used (<code class="literal">default</code>) and also some default boot arguments for the Java VM when the host controller boots an instance. It also binds a <code class="literal">socket-binding-group</code> to the server group.
				</p><div class="formalpara"><p class="title"><strong>server group</strong></p><p>
						
<pre class="programlisting language-xml">    &lt;server-groups&gt;
        &lt;!-- load-balancer-group should be removed in production systems and replaced with a better software or hardware based one --&gt;
        &lt;server-group name="load-balancer-group" profile="load-balancer"&gt;
            &lt;jvm name="default"&gt;
                &lt;heap size="64m" max-size="512m"/&gt;
            &lt;/jvm&gt;
            &lt;socket-binding-group ref="load-balancer-sockets"/&gt;
        &lt;/server-group&gt;
        &lt;server-group name="auth-server-group" profile="auth-server-clustered"&gt;
            &lt;jvm name="default"&gt;
                &lt;heap size="64m" max-size="512m"/&gt;
            &lt;/jvm&gt;
            &lt;socket-binding-group ref="ha-sockets"/&gt;
        &lt;/server-group&gt;
    &lt;/server-groups&gt;</pre>
					</p></div></section><section class="section" id="host_controller_configuration"><div class="titlepage"><div><div><h3 class="title">3.3.2. Host Controller Configuration</h3></div></div></div><p>
					Red Hat Single Sign-On comes with two host controller configuration files that reside in the <span class="emphasis"><em>…​/domain/configuration/</em></span> directory: <span class="emphasis"><em>host-master.xml</em></span> and <span class="emphasis"><em>host-slave.xml</em></span>. <span class="emphasis"><em>host-master.xml</em></span> is configured to boot up a domain controller, a load balancer, and one Red Hat Single Sign-On server instance. <span class="emphasis"><em>host-slave.xml</em></span> is configured to talk to the domain controller and boot up one Red Hat Single Sign-On server instance.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						The load balancer is not a required service. It exists so that you can easily test drive clustering on your development machine. While usable in production, you have the option of replacing it if you have a different hardware or software based load balancer you want to use.
					</p></div></div><div class="formalpara"><p class="title"><strong>Host Controller Config</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/host-files.png" alt="host files"/></span>
					</p></div><p>
					To disable the load balancer server instance, edit <span class="emphasis"><em>host-master.xml</em></span> and comment out or remove the <code class="literal">"load-balancer"</code> entry.
				</p><pre class="programlisting language-xml">    &lt;servers&gt;
        &lt;!-- remove or comment out next line --&gt;
        &lt;server name="load-balancer" group="loadbalancer-group"/&gt;
        ...
    &lt;/servers&gt;</pre><p>
					Another interesting thing to note about this file is the declaration of the authentication server instance. It has a <code class="literal">port-offset</code> setting. Any network port defined in the <span class="emphasis"><em>domain.xml</em></span> <code class="literal">socket-binding-group</code> or the server group will have the value of <code class="literal">port-offset</code> added to it. For this example domain setup we do this so that ports opened by the load balancer server don’t conflict with the authentication server instance that is started.
				</p><pre class="programlisting language-xml">    &lt;servers&gt;
        ...
        &lt;server name="server-one" group="auth-server-group" auto-start="true"&gt;
             &lt;socket-bindings port-offset="150"/&gt;
        &lt;/server&gt;
    &lt;/servers&gt;</pre></section><section class="section" id="server_instance_working_directories"><div class="titlepage"><div><div><h3 class="title">3.3.3. Server Instance Working Directories</h3></div></div></div><p>
					Each Red Hat Single Sign-On server instance defined in your host files creates a working directory under <span class="emphasis"><em>…​/domain/servers/{SERVER NAME}</em></span>. Additional configuration can be put there, and any temporary, log, or data files the server instance needs or creates go there too. The structure of these per server directories ends up looking like any other JBoss EAP booted server.
				</p><div class="formalpara"><p class="title"><strong>Working Directories</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/domain-server-dir.png" alt="domain server dir"/></span>
					</p></div></section><section class="section" id="domain_boot_script"><div class="titlepage"><div><div><h3 class="title">3.3.4. Domain Boot Script</h3></div></div></div><p>
					When running the server in domain mode, there is a specific script you need to run to boot the server depending on your operating system. These scripts live in the <span class="emphasis"><em>bin/</em></span> directory of the server distribution.
				</p><div class="formalpara"><p class="title"><strong>Domain Boot Script</strong></p><p>
						<span class="inlinemediaobject"><img src="images/rhsso-images/domain-boot-files.png" alt="domain boot files"/></span>
					</p></div><p>
					To boot the server:
				</p><div class="formalpara"><p class="title"><strong>Linux/Unix</strong></p><p>
						
<pre class="screen">$ .../bin/domain.sh --host-config=host-master.xml</pre>
					</p></div><div class="formalpara"><p class="title"><strong>Windows</strong></p><p>
						
<pre class="screen">&gt; ...\bin\domain.bat --host-config=host-master.xml</pre>
					</p></div><p>
					When running the boot script you will need pass in the host controlling configuration file you are going to use via the <code class="literal">--host-config</code> switch.
				</p></section><section class="section" id="clustered-domain-example"><div class="titlepage"><div><div><h3 class="title">3.3.5. Clustered Domain Example</h3></div></div></div><p>
					You can test drive clustering using the out-of-the-box <span class="emphasis"><em>domain.xml</em></span> configuration. This example domain is meant to run on one machine and boots up:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							a domain controller
						</li><li class="listitem">
							an HTTP load balancer
						</li><li class="listitem">
							2 Red Hat Single Sign-On server instances
						</li></ul></div><p>
					To simulate running a cluster on two machines, you’ll run the <code class="literal">domain.sh</code> script twice to start two separate host controllers. The first will be the master host controller which will start a domain controller, an HTTP load balancer, and one Red Hat Single Sign-On authentication server instance. The second will be a slave host controller that only starts up an authentication server instance.
				</p><section class="section" id="setup_slave_connection_to_domain_controller"><div class="titlepage"><div><div><h4 class="title">3.3.5.1. Setup Slave Connection to Domain Controller</h4></div></div></div><p>
						Before you can boot things up though, you have to configure the slave host controller so that it can talk securely to the domain controller. If you do not do this, then the slave host will not be able to obtain the centralized configuration from the domain controller. To set up a secure connection, you have to create a server admin user and a secret that will be shared between the master and the slave. You do this by running the <code class="literal">…​/bin/add-user.sh</code> script.
					</p><p>
						When you run the script select <code class="literal">Management User</code> and answer <code class="literal">yes</code> when it asks you if the new user is going to be used for one AS process to connect to another. This will generate a secret that you’ll need to cut and paste into the <span class="emphasis"><em>…​/domain/configuration/host-slave.xml</em></span> file.
					</p><div class="formalpara"><p class="title"><strong>Add App Server Admin</strong></p><p>
							
<pre class="screen">$ add-user.sh
 What type of user do you wish to add?
  a) Management User (mgmt-users.properties)
  b) Application User (application-users.properties)
 (a): a
 Enter the details of the new user to add.
 Using realm 'ManagementRealm' as discovered from the existing property files.
 Username : admin
 Password recommendations are listed below. To modify these restrictions edit the add-user.properties configuration file.
  - The password should not be one of the following restricted values {root, admin, administrator}
  - The password should contain at least 8 characters, 1 alphabetic character(s), 1 digit(s), 1 non-alphanumeric symbol(s)
  - The password should be different from the username
 Password :
 Re-enter Password :
 What groups do you want this user to belong to? (Please enter a comma separated list, or leave blank for none)[ ]:
 About to add user 'admin' for realm 'ManagementRealm'
 Is this correct yes/no? yes
 Added user 'admin' to file '/.../standalone/configuration/mgmt-users.properties'
 Added user 'admin' to file '/.../domain/configuration/mgmt-users.properties'
 Added user 'admin' with groups to file '/.../standalone/configuration/mgmt-groups.properties'
 Added user 'admin' with groups to file '/.../domain/configuration/mgmt-groups.properties'
 Is this new user going to be used for one AS process to connect to another AS process?
 e.g. for a slave host controller connecting to the master or for a Remoting connection for server to server EJB calls.
 yes/no? yes
 To represent the user add the following to the server-identities definition &lt;secret value="bWdtdDEyMyE=" /&gt;</pre>
						</p></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							The add-user.sh does not add user to Red Hat Single Sign-On server but to the underlying JBoss Enterprise Application Platform. The credentials used and generated in the above script are only for example purpose. Please use the ones generated on your system.
						</p></div></div><p>
						Now cut and paste the secret value into the <span class="emphasis"><em>…​/domain/configuration/host-slave.xml</em></span> file as follows:
					</p><pre class="programlisting language-xml">     &lt;management&gt;
         &lt;security-realms&gt;
             &lt;security-realm name="ManagementRealm"&gt;
                 &lt;server-identities&gt;
                     &lt;secret value="bWdtdDEyMyE="/&gt;
                 &lt;/server-identities&gt;</pre><p>
						You will also need to add the <span class="emphasis"><em>username</em></span> of the created user in the <span class="emphasis"><em>…​/domain/configuration/host-slave.xml</em></span> file:
					</p><pre class="programlisting language-xml">     &lt;remote security-realm="ManagementRealm" username="admin"&gt;</pre></section><section class="section" id="run_the_boot_scripts"><div class="titlepage"><div><div><h4 class="title">3.3.5.2. Run the Boot Scripts</h4></div></div></div><p>
						Since we’re simulating a two node cluster on one development machine, you’ll run the boot script twice:
					</p><div class="formalpara"><p class="title"><strong>Boot up master</strong></p><p>
							
<pre class="programlisting language-shell">$ domain.sh --host-config=host-master.xml</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Boot up slave</strong></p><p>
							
<pre class="programlisting language-shell">$ domain.sh --host-config=host-slave.xml</pre>
						</p></div><p>
						To try it out, open your browser and go to <a class="link" href="http://localhost:8080/auth">http://localhost:8080/auth</a>.
					</p></section></section></section><section class="section" id="crossdc-mode"><div class="titlepage"><div><div><h2 class="title">3.4. Cross-Datacenter Replication Mode</h2></div></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					Cross-Datacenter Replication Mode is Technology Preview and is not fully supported.
				</p></div></div><p>
				Cross-Datacenter Replication mode is for when you want to run Red Hat Single Sign-On in a cluster across multiple data centers, most typically using data center sites that are in different geographic regions. When using this mode, each data center will have its own cluster of Red Hat Single Sign-On servers.
			</p><p>
				This documentation will refer the following example architecture diagram to illustrate and describe a simple Cross-Datacenter Replication use case.
			</p><div id="archdiagram" class="formalpara"><p class="title"><strong>Example Architecture Diagram</strong></p><p>
					<span class="inlinemediaobject"><img src="images/rhsso-images/cross-dc-architecture.png" alt="cross dc architecture"/></span>
				</p></div><section class="section" id="prerequisites"><div class="titlepage"><div><div><h3 class="title">3.4.1. Prerequisites</h3></div></div></div><p>
					As this is an advanced topic, we recommend you first read the following, which provide valuable background knowledge:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_installation_and_configuration_guide/#_clustering">Clustering with Red Hat Single Sign-On</a> When setting up for Cross-Datacenter Replication, you will use more independent Red Hat Single Sign-On clusters, so you must understand how a cluster works and the basic concepts and requirements such as load balancing, shared databases, and multicasting.
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/7.3/html/red_hat_data_grid_user_guide/x_site_replication">JBoss Data Grid Cross-Datacenter Replication</a> Red Hat Single Sign-On uses JBoss Data Grid (JDG) for the replication of Infinispan data between the data centers.
						</li></ul></div></section><section class="section" id="technicaldetails"><div class="titlepage"><div><div><h3 class="title">3.4.2. Technical details</h3></div></div></div><p>
					This section provides an introduction to the concepts and details of how Red Hat Single Sign-On Cross-Datacenter Replication is accomplished.
				</p><div class="formalpara"><p class="title"><strong>Data</strong></p><p>
						Red Hat Single Sign-On is stateful application. It uses the following as data sources:
					</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							A database is used to persist permanent data, such as user information.
						</li><li class="listitem">
							An Infinispan cache is used to cache persistent data from the database and also to save some short-lived and frequently-changing metadata, such as for user sessions. Infinispan is usually much faster than a database, however the data saved using Infinispan are not permanent and is not expected to persist across cluster restarts.
						</li></ul></div><p>
					In our example architecture, there are two data centers called <code class="literal">site1</code> and <code class="literal">site2</code>. For Cross-Datacenter Replication, we must make sure that both sources of data work reliably and that Red Hat Single Sign-On servers from <code class="literal">site1</code> are eventually able to read the data saved by Red Hat Single Sign-On servers on <code class="literal">site2</code> .
				</p><p>
					Based on the environment, you have the option to decide if you prefer:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Reliability - which is typically used in Active/Active mode. Data written on <code class="literal">site1</code> must be visible immediately on <code class="literal">site2</code>.
						</li><li class="listitem">
							Performance - which is typically used in Active/Passive mode. Data written on <code class="literal">site1</code> does not need to be visible immediately on <code class="literal">site2</code>. In some cases, the data may not be visible on <code class="literal">site2</code> at all.
						</li></ul></div><p>
					For more details, see <a class="xref" href="#modes" title="3.4.4. Modes">Section 3.4.4, “Modes”</a>.
				</p></section><section class="section" id="requestprocessing"><div class="titlepage"><div><div><h3 class="title">3.4.3. Request processing</h3></div></div></div><p>
					An end user’s browser sends an HTTP request to the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_installation_and_configuration_guide/#_setting-up-a-load-balancer-or-proxy">front end load balancer</a>. This load balancer is usually HTTPD or WildFly with mod_cluster, NGINX, HA Proxy, or perhaps some other kind of software or hardware load balancer.
				</p><p>
					The load balancer then forwards the HTTP requests it receives to the underlying Red Hat Single Sign-On instances, which can be spread among multiple data centers. Load balancers typically offer support for <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_installation_and_configuration_guide/#sticky-sessions">sticky sessions</a>, which means that the load balancer is able to always forward all HTTP requests from the same user to the same Red Hat Single Sign-On instance in same data center.
				</p><p>
					HTTP requests that are sent from client applications to the load balancer are called <code class="literal">backchannel requests</code>. These are not seen by an end user’s browser and therefore can not be part of a sticky session between the user and the load balancer. For backchannel requests, the loadbalancer can forward the HTTP request to any Red Hat Single Sign-On instance in any data center. This is challenging as some OpenID Connect and some SAML flows require multiple HTTP requests from both the user and the application. Because we can not reliably depend on sticky sessions to force all the related requests to be sent to the same Red Hat Single Sign-On instance in the same data center, we must instead replicate some data across data centers, so the data are seen by subsequent HTTP requests during a particular flow.
				</p></section><section class="section" id="modes"><div class="titlepage"><div><div><h3 class="title">3.4.4. Modes</h3></div></div></div><p>
					According your requirements, there are two basic operating modes for Cross-Datacenter Replication:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Active/Passive - Here the users and client applications send the requests just to the Red Hat Single Sign-On nodes in just a single data center. The second data center is used just as a <code class="literal">backup</code> for saving the data. In case of the failure in the main data center, the data can be usually restored from the second data center.
						</li><li class="listitem">
							Active/Active - Here the users and client applications send the requests to the Red Hat Single Sign-On nodes in both data centers. It means that data need to be visible immediately on both sites and available to be consumed immediately from Red Hat Single Sign-On servers on both sites. This is especially true if Red Hat Single Sign-On server writes some data on <code class="literal">site1</code>, and it is required that the data are available immediately for reading by Red Hat Single Sign-On servers on <code class="literal">site2</code> immediately after the write on <code class="literal">site1</code> is finished.
						</li></ul></div><p>
					The active/passive mode is better for performance. For more information about how to configure caches for either mode, see: <a class="xref" href="#backups" title="3.4.14. SYNC or ASYNC backups">Section 3.4.14, “SYNC or ASYNC backups”</a>.
				</p></section><section class="section" id="database"><div class="titlepage"><div><div><h3 class="title">3.4.5. Database</h3></div></div></div><p>
					Red Hat Single Sign-On uses a relational database management system (RDBMS) to persist some metadata about realms, clients, users, and so on. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_installation_and_configuration_guide/#_database">this chapter</a> of the server installation guide for more details. In a Cross-Datacenter Replication setup, we assume that either both data centers talk to the same database or that every data center has its own database node and both database nodes are synchronously replicated across the data centers. In both cases, it is required that when a Red Hat Single Sign-On server on <code class="literal">site1</code> persists some data and commits the transaction, those data are immediately visible by subsequent DB transactions on <code class="literal">site2</code>.
				</p><p>
					Details of DB setup are out-of-scope for Red Hat Single Sign-On, however many RDBMS vendors like MariaDB and Oracle offer replicated databases and synchronous replication. We test Red Hat Single Sign-On with these vendors:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Oracle Database 12c Release 1 (12.1) RAC
						</li><li class="listitem">
							Galera 3.12 cluster for MariaDB server version 10.1.19-MariaDB
						</li></ul></div></section><section class="section" id="cache"><div class="titlepage"><div><div><h3 class="title">3.4.6. Infinispan caches</h3></div></div></div><p>
					This section begins with a high level description of the Infinispan caches. More details of the cache setup follow.
				</p><div class="formalpara"><p class="title"><strong>Authentication sessions</strong></p><p>
						In Red Hat Single Sign-On we have the concept of authentication sessions. There is a separate Infinispan cache called <code class="literal">authenticationSessions</code> used to save data during authentication of particular user. Requests from this cache usually involve only a browser and the Red Hat Single Sign-On server, not the application. Here we can rely on sticky sessions and the <code class="literal">authenticationSessions</code> cache content does not need to be replicated across data centers, even if you are in Active/Active mode.
					</p></div><div class="formalpara"><p class="title"><strong>Caching and invalidation of persistent data</strong></p><p>
						Red Hat Single Sign-On uses Infinispan to cache persistent data to avoid many unnecessary requests to the database. Caching improves performance, however it adds an additional challenge. When some Red Hat Single Sign-On server updates any data, all other Red Hat Single Sign-On servers in all data centers need to be aware of it, so they invalidate particular data from their caches. Red Hat Single Sign-On uses local Infinispan caches called <code class="literal">realms</code>, <code class="literal">users</code>, and <code class="literal">authorization</code> to cache persistent data.
					</p></div><p>
					We use a separate cache, <code class="literal">work</code>, which is replicated across all data centers. The work cache itself does not cache any real data. It is used only for sending invalidation messages between cluster nodes and data centers. In other words, when data is updated, such as the user <code class="literal">john</code>, the Red Hat Single Sign-On node sends the invalidation message to all other cluster nodes in the same data center and also to all other data centers. After receiving the invalidation notice, every node then invalidates the appropriate data from their local cache.
				</p><div class="formalpara"><p class="title"><strong>User sessions</strong></p><p>
						There are Infinispan caches called <code class="literal">sessions</code>, <code class="literal">clientSessions</code>, <code class="literal">offlineSessions</code>, and <code class="literal">offlineClientSessions</code>, all of which usually need to be replicated across data centers. These caches are used to save data about user sessions, which are valid for the length of a user’s browser session. The caches must handle the HTTP requests from the end user and from the application. As described above, sticky sessions can not be reliably used in this instance, but we still want to ensure that subsequent HTTP requests can see the latest data. For this reason, the data are usually replicated across data centers.
					</p></div><div class="formalpara"><p class="title"><strong>Brute force protection</strong></p><p>
						Finally the <code class="literal">loginFailures</code> cache is used to track data about failed logins, such as how many times the user <code class="literal">john</code> entered a bad password. The details are described <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_administration_guide/#password-guess-brute-force-attacks">here</a>. It is up to the admin whether this cache should be replicated across data centers. To have an accurate count of login failures, the replication is needed. On the other hand, not replicating this data can save some performance. So if performance is more important than accurate counts of login failures, the replication can be avoided.
					</p></div><p>
					For more detail about how caches can be configured see <a class="xref" href="#tuningcache" title="3.4.13. Tuning the JDG cache configuration">Section 3.4.13, “Tuning the JDG cache configuration”</a>.
				</p></section><section class="section" id="communication"><div class="titlepage"><div><div><h3 class="title">3.4.7. Communication details</h3></div></div></div><p>
					Red Hat Single Sign-On uses multiple, separate clusters of Infinispan caches. Every Red Hat Single Sign-On node is in the cluster with the other Red Hat Single Sign-On nodes in same data center, but not with the Red Hat Single Sign-On nodes in different data centers. A Red Hat Single Sign-On node does not communicate directly with the Red Hat Single Sign-On nodes from different data centers. Red Hat Single Sign-On nodes use external JDG (actually JDG servers) for communication across data centers. This is done using the <a class="link" href="https://infinispan.org/docs/8.2.x/user_guide/user_guide.html#using_hot_rod_server">Infinispan HotRod protocol</a>.
				</p><p>
					The Infinispan caches on the Red Hat Single Sign-On side must be configured with the <a class="link" href="https://infinispan.org/docs/8.2.x/user_guide/user_guide.html#remote_store">remoteStore</a> to ensure that data are saved to the remote cache. There is separate Infinispan cluster between JDG servers, so the data saved on JDG1 on <code class="literal">site1</code> are replicated to JDG2 on <code class="literal">site2</code> .
				</p><p>
					Finally, the receiving JDG server notifies the Red Hat Single Sign-On servers in its cluster through the Client Listeners, which are a feature of the HotRod protocol. Red Hat Single Sign-On nodes on <code class="literal">site2</code> then update their Infinispan caches and the particular user session is also visible on Red Hat Single Sign-On nodes on <code class="literal">site2</code>.
				</p><p>
					See the <a class="xref" href="#archdiagram" title="Example Architecture Diagram">Example Architecture Diagram</a> for more details.
				</p></section><section class="section" id="setup"><div class="titlepage"><div><div><h3 class="title">3.4.8. Basic setup</h3></div></div></div><p>
					For this example, we describe using two data centers, <code class="literal">site1</code> and <code class="literal">site2</code>. Each data center consists of 1 JDG server and 2 Red Hat Single Sign-On servers. We will end up with 2 JDG servers and 4 Red Hat Single Sign-On servers in total.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">Site1</code> consists of JDG server, <code class="literal">jdg1</code>, and 2 Red Hat Single Sign-On servers, <code class="literal">node11</code> and <code class="literal">node12</code> .
						</li><li class="listitem">
							<code class="literal">Site2</code> consists of JDG server, <code class="literal">jdg2</code>, and 2 Red Hat Single Sign-On servers, <code class="literal">node21</code> and <code class="literal">node22</code> .
						</li><li class="listitem">
							JDG servers <code class="literal">jdg1</code> and <code class="literal">jdg2</code> are connected to each other through the RELAY2 protocol and <code class="literal">backup</code> based JDG caches in a similar way as described in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/7.3/html/red_hat_data_grid_user_guide/x_site_replication">JDG documentation</a>.
						</li><li class="listitem">
							Red Hat Single Sign-On servers <code class="literal">node11</code> and <code class="literal">node12</code> form a cluster with each other, but they do not communicate directly with any server in <code class="literal">site2</code>. They communicate with the Infinispan server <code class="literal">jdg1</code> using the HotRod protocol (Remote cache). See <a class="xref" href="#communication" title="3.4.7. Communication details">Section 3.4.7, “Communication details”</a> for the details.
						</li><li class="listitem">
							The same details apply for <code class="literal">node21</code> and <code class="literal">node22</code>. They cluster with each other and communicate only with <code class="literal">jdg2</code> server using the HotRod protocol.
						</li></ul></div><p>
					Our example setup assumes all that all 4 Red Hat Single Sign-On servers talk to the same database. In production, it is recommended to use separate synchronously replicated databases across data centers as described in <a class="xref" href="#database" title="3.4.5. Database">Section 3.4.5, “Database”</a>.
				</p><section class="section" id="jdgsetup"><div class="titlepage"><div><div><h4 class="title">3.4.8.1. JDG server setup</h4></div></div></div><p>
						Follow these steps to set up the JDG server:
					</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Download JDG 7.3.0 server and unzip to a directory you choose. This location will be referred in later steps as <code class="literal">JDG1_HOME</code> .
							</li><li class="listitem"><p class="simpara">
								Change those things in the <code class="literal">JDG1_HOME/standalone/configuration/clustered.xml</code> in the configuration of JGroups subsystem:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Add the <code class="literal">xsite</code> channel, which will use <code class="literal">tcp</code> stack, under <code class="literal">channels</code> element:
									</p><pre class="programlisting language-xml">&lt;channels default="cluster"&gt;
    &lt;channel name="cluster"/&gt;
    &lt;channel name="xsite" stack="tcp"/&gt;
&lt;/channels&gt;</pre></li><li class="listitem"><p class="simpara">
										Add a <code class="literal">relay</code> element to the end of the <code class="literal">udp</code> stack. We will configure it in a way that our site is <code class="literal">site1</code> and the other site, where we will backup, is <code class="literal">site2</code>:
									</p><pre class="programlisting language-xml">&lt;stack name="udp"&gt;
    ...
    &lt;relay site="site1"&gt;
        &lt;remote-site name="site2" channel="xsite"/&gt;
        &lt;property name="relay_multicasts"&gt;false&lt;/property&gt;
    &lt;/relay&gt;
&lt;/stack&gt;</pre></li><li class="listitem"><p class="simpara">
										Configure the <code class="literal">tcp</code> stack to use <code class="literal">TCPPING</code> protocol instead of <code class="literal">MPING</code>. Remove the <code class="literal">MPING</code> element and replace it with the <code class="literal">TCPPING</code>. The <code class="literal">initial_hosts</code> element points to the hosts <code class="literal">jdg1</code> and <code class="literal">jdg2</code>:
									</p><pre class="programlisting language-xml">&lt;stack name="tcp"&gt;
    &lt;transport type="TCP" socket-binding="jgroups-tcp"/&gt;
    &lt;protocol type="TCPPING"&gt;
        &lt;property name="initial_hosts"&gt;jdg1[7600],jdg2[7600]&lt;/property&gt;
        &lt;property name="ergonomics"&gt;false&lt;/property&gt;
    &lt;/protocol&gt;
    &lt;protocol type="MERGE3"/&gt;
    ...
&lt;/stack&gt;</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
											This is just an example setup to have things quickly running. In production, you are not required to use <code class="literal">tcp</code> stack for the JGroups <code class="literal">RELAY2</code>, but you can configure any other stack. For example, you could use the default udp stack, if the network between your data centers is able to support multicast. Just make sure that the JDG and Red Hat Single Sign-On clusters are mutually indiscoverable. Similarly, you are not required to use <code class="literal">TCPPING</code> as discovery protocol. And in production, you probably won’t use <code class="literal">TCPPING</code> due it’s static nature. Finally, site names are also configurable. Details of this more-detailed setup are out-of-scope of the Red Hat Single Sign-On documentation. See the JDG documentation and JGroups documentation for more details.
										</p></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Add this into <code class="literal">JDG1_HOME/standalone/configuration/clustered.xml</code> under cache-container named <code class="literal">clustered</code>:
							</p><pre class="programlisting language-xml">&lt;cache-container name="clustered" default-cache="default" statistics="true"&gt;
        ...
        &lt;replicated-cache-configuration name="sessions-cfg" mode="SYNC" start="EAGER" batching="false"&gt;
            &lt;transaction mode="NON_DURABLE_XA" locking="PESSIMISTIC"/&gt;
            &lt;locking acquire-timeout="0" /&gt;
            &lt;backups&gt;
                &lt;backup site="site2" failure-policy="FAIL" strategy="SYNC" enabled="true"&gt;
                    &lt;take-offline min-wait="60000" after-failures="3" /&gt;
                &lt;/backup&gt;
            &lt;/backups&gt;
        &lt;/replicated-cache-configuration&gt;

        &lt;replicated-cache name="work" configuration="sessions-cfg"/&gt;
        &lt;replicated-cache name="sessions" configuration="sessions-cfg"/&gt;
        &lt;replicated-cache name="clientSessions" configuration="sessions-cfg"/&gt;
        &lt;replicated-cache name="offlineSessions" configuration="sessions-cfg"/&gt;
        &lt;replicated-cache name="offlineClientSessions" configuration="sessions-cfg"/&gt;
        &lt;replicated-cache name="actionTokens" configuration="sessions-cfg"/&gt;
        &lt;replicated-cache name="loginFailures" configuration="sessions-cfg"/&gt;

&lt;/cache-container&gt;</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									Details about the configuration options inside <code class="literal">replicated-cache-configuration</code> are explained in <a class="xref" href="#tuningcache" title="3.4.13. Tuning the JDG cache configuration">Section 3.4.13, “Tuning the JDG cache configuration”</a>, which includes information about tweaking some of those options.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Some JDG server releases require authorization before accessing protected caches over network.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									You should not see any issue if you use recommended JDG 7.3.0 server and this step can (and should) be ignored. Issues related to authorization may exist just for some other versions of JDG server.
								</p></div></div><p class="simpara">
								Red Hat Single Sign-On requires updates to <code class="literal">___script_cache</code> cache containing scripts. If you get errors accessing this cache, you will need to set up authorization in <code class="literal">clustered.xml</code> configuration as described below:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										In the <code class="literal">&lt;management&gt;</code> section, add a security realm:
									</p><pre class="programlisting language-xml">&lt;management&gt;
    &lt;security-realms&gt;
        ...
        &lt;security-realm name="AllowScriptManager"&gt;
            &lt;authentication&gt;
                &lt;users&gt;
                    &lt;user username="___script_manager"&gt;
                        &lt;password&gt;not-so-secret-password&lt;/password&gt;
                    &lt;/user&gt;
                &lt;/users&gt;
            &lt;/authentication&gt;
        &lt;/security-realm&gt;
    &lt;/security-realms&gt;</pre></li><li class="listitem"><p class="simpara">
										In the server core subsystem, add <code class="literal">&lt;security&gt;</code> as below:
									</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:infinispan:server:core:8.4"&gt;
    &lt;cache-container name="clustered" default-cache="default" statistics="true"&gt;
        &lt;security&gt;
            &lt;authorization&gt;
                &lt;identity-role-mapper/&gt;
                &lt;role name="___script_manager" permissions="ALL"/&gt;
            &lt;/authorization&gt;
        &lt;/security&gt;
        ...</pre></li><li class="listitem"><p class="simpara">
										In the endpoint subsystem, add authentication configuration to Hot Rod connector:
									</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:infinispan:server:endpoint:8.1"&gt;
    &lt;hotrod-connector cache-container="clustered" socket-binding="hotrod"&gt;
        ...
        &lt;authentication security-realm="AllowScriptManager"&gt;
            &lt;sasl mechanisms="DIGEST-MD5" qop="auth" server-name="keycloak-jdg-server"&gt;
                &lt;policy&gt;
                    &lt;no-anonymous value="false" /&gt;
                &lt;/policy&gt;
            &lt;/sasl&gt;
        &lt;/authentication&gt;</pre></li></ol></div></li><li class="listitem">
								Copy the server to the second location, which will be referred to later as <code class="literal">JDG2_HOME</code>.
							</li><li class="listitem"><p class="simpara">
								In the <code class="literal">JDG2_HOME/standalone/configuration/clustered.xml</code> exchange <code class="literal">site1</code> with <code class="literal">site2</code> and vice versa, both in the configuration of <code class="literal">relay</code> in the JGroups subsystem and in configuration of <code class="literal">backups</code> in the cache-subsystem. For example:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										The <code class="literal">relay</code> element should look like this:
									</p><pre class="programlisting language-xml">&lt;relay site="site2"&gt;
    &lt;remote-site name="site1" channel="xsite"/&gt;
    &lt;property name="relay_multicasts"&gt;false&lt;/property&gt;
&lt;/relay&gt;</pre></li><li class="listitem"><p class="simpara">
										The <code class="literal">backups</code> element like this:
									</p><pre class="programlisting language-xml">            &lt;backups&gt;
                &lt;backup site="site1" ....
                ...</pre><p class="simpara">
										It is currently required to have different configuration files for the JDG servers on both sites as the Infinispan subsystem does not support replacing site names with expressions. See <a class="link" href="https://issues.jboss.org/browse/WFLY-9458">this issue</a> for more details.
									</p></li></ol></div></li><li class="listitem"><p class="simpara">
								Start server <code class="literal">jdg1</code>:
							</p><pre class="screen">cd JDG1_HOME/bin
./standalone.sh -c clustered.xml -Djava.net.preferIPv4Stack=true \
  -Djboss.default.multicast.address=234.56.78.99 \
  -Djboss.node.name=jdg1 -b <span class="emphasis"><em>PUBLIC_IP_ADDRESS</em></span></pre></li><li class="listitem"><p class="simpara">
								Start server <code class="literal">jdg2</code>. There is a different multicast address, so the <code class="literal">jdg1</code> and <code class="literal">jdg2</code> servers are not directly clustered with each other; rather, they are just connected through the RELAY2 protocol, and the TCP JGroups stack is used for communication between them. The start up command looks like this:
							</p><pre class="screen">cd JDG2_HOME/bin
./standalone.sh -c clustered.xml -Djava.net.preferIPv4Stack=true \
  -Djboss.default.multicast.address=234.56.78.100 \
  -Djboss.node.name=jdg2 -b <span class="emphasis"><em>PUBLIC_IP_ADDRESS</em></span></pre></li><li class="listitem"><p class="simpara">
								To verify that channel works at this point, you may need to use JConsole and connect either to the running <code class="literal">JDG1</code> or the <code class="literal">JDG2</code> server. When you use the MBean <code class="literal">jgroups:type=protocol,cluster="cluster",protocol=RELAY2</code> and operation <code class="literal">printRoutes</code>, you should see output like this:
							</p><pre class="screen">site1 --&gt; _jdg1:site1
site2 --&gt; _jdg2:site2</pre><p class="simpara">
								When you use the MBean <code class="literal">jgroups:type=protocol,cluster="cluster",protocol=GMS</code>, you should see that the attribute member contains just single member:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										On <code class="literal">JDG1</code> it should be like this:
									</p><pre class="screen">(1) jdg1</pre></li><li class="listitem"><p class="simpara">
										And on JDG2 like this:
									</p><pre class="screen">(1) jdg2</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
											In production, you can have more JDG servers in every data center. You just need to ensure that JDG servers in same data center are using the same multicast address (In other words, the same <code class="literal">jboss.default.multicast.address</code> during startup). Then in jconsole in <code class="literal">GMS</code> protocol view, you will see all the members of current cluster.
										</p></div></div></li></ol></div></li></ol></div></section><section class="section" id="serversetup"><div class="titlepage"><div><div><h4 class="title">3.4.8.2. Red Hat Single Sign-On servers setup</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Unzip Red Hat Single Sign-On server distribution to a location you choose. It will be referred to later as <code class="literal">NODE11</code>.
							</li><li class="listitem"><p class="simpara">
								Configure a shared database for KeycloakDS datasource. It is recommended to use MySQL or MariaDB for testing purposes. See <a class="xref" href="#database" title="3.4.5. Database">Section 3.4.5, “Database”</a> for more details.
							</p><p class="simpara">
								In production you will likely need to have a separate database server in every data center and both database servers should be synchronously replicated to each other. In the example setup, we just use a single database and connect all 4 Red Hat Single Sign-On servers to it.
							</p></li><li class="listitem"><p class="simpara">
								Edit <code class="literal">NODE11/standalone/configuration/standalone-ha.xml</code> :
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Add the attribute <code class="literal">site</code> to the JGroups UDP protocol:
									</p><pre class="programlisting language-xml">                  &lt;stack name="udp"&gt;
                      &lt;transport type="UDP" socket-binding="jgroups-udp" site="${jboss.site.name}"/&gt;</pre></li><li class="listitem"><p class="simpara">
										Add this <code class="literal">module</code> attribute under <code class="literal">cache-container</code> element of name <code class="literal">keycloak</code> :
									</p><pre class="programlisting language-xml"> &lt;cache-container name="keycloak" module="org.keycloak.keycloak-model-infinispan"&gt;</pre></li><li class="listitem"><p class="simpara">
										Add the <code class="literal">remote-store</code> under <code class="literal">work</code> cache:
									</p><pre class="programlisting language-xml">&lt;replicated-cache name="work"&gt;
    &lt;remote-store cache="work" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="false" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/replicated-cache&gt;</pre></li><li class="listitem"><p class="simpara">
										Add the <code class="literal">remote-store</code> like this under <code class="literal">sessions</code> cache:
									</p><pre class="programlisting language-xml">&lt;distributed-cache name="sessions" owners="1"&gt;
    &lt;remote-store cache="sessions" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="false" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/distributed-cache&gt;</pre></li><li class="listitem"><p class="simpara">
										Do the same for <code class="literal">offlineSessions</code>, <code class="literal">clientSessions</code>, <code class="literal">offlineClientSessions</code>, <code class="literal">loginFailures</code>, and <code class="literal">actionTokens</code> caches (the only difference from <code class="literal">sessions</code> cache is that <code class="literal">cache</code> property value are different):
									</p><pre class="programlisting language-xml">&lt;distributed-cache name="offlineSessions" owners="1"&gt;
    &lt;remote-store cache="offlineSessions" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="false" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/distributed-cache&gt;

&lt;distributed-cache name="clientSessions" owners="1"&gt;
    &lt;remote-store cache="clientSessions" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="false" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/distributed-cache&gt;

&lt;distributed-cache name="offlineClientSessions" owners="1"&gt;
    &lt;remote-store cache="offlineClientSessions" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="false" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/distributed-cache&gt;

&lt;distributed-cache name="loginFailures" owners="1"&gt;
    &lt;remote-store cache="loginFailures" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="false" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/distributed-cache&gt;

&lt;distributed-cache name="actionTokens" owners="2"&gt;
    &lt;object-memory size="-1"/&gt;
    &lt;expiration max-idle="-1" interval="300000"/&gt;
    &lt;remote-store cache="actionTokens" remote-servers="remote-cache" passivation="false" fetch-state="false" purge="false" preload="true" shared="true"&gt;
        &lt;property name="rawValues"&gt;true&lt;/property&gt;
        &lt;property name="marshaller"&gt;org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory&lt;/property&gt;
        &lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;
    &lt;/remote-store&gt;
&lt;/distributed-cache&gt;</pre></li><li class="listitem"><p class="simpara">
										Add outbound socket binding for the remote store into <code class="literal">socket-binding-group</code> element configuration:
									</p><pre class="programlisting language-xml">&lt;outbound-socket-binding name="remote-cache"&gt;
    &lt;remote-destination host="${remote.cache.host:localhost}" port="${remote.cache.port:11222}"/&gt;
&lt;/outbound-socket-binding&gt;</pre></li><li class="listitem">
										The configuration of distributed cache <code class="literal">authenticationSessions</code> and other caches is left unchanged.
									</li><li class="listitem"><p class="simpara">
										Optionally enable DEBUG logging under the <code class="literal">logging</code> subsystem:
									</p><pre class="programlisting language-xml">&lt;logger category="org.keycloak.cluster.infinispan"&gt;
    &lt;level name="DEBUG"/&gt;
&lt;/logger&gt;
&lt;logger category="org.keycloak.connections.infinispan"&gt;
    &lt;level name="DEBUG"/&gt;
&lt;/logger&gt;
&lt;logger category="org.keycloak.models.cache.infinispan"&gt;
    &lt;level name="DEBUG"/&gt;
&lt;/logger&gt;
&lt;logger category="org.keycloak.models.sessions.infinispan"&gt;
    &lt;level name="DEBUG"/&gt;
&lt;/logger&gt;</pre></li></ol></div></li><li class="listitem">
								Copy the <code class="literal">NODE11</code> to 3 other directories referred later as <code class="literal">NODE12</code>, <code class="literal">NODE21</code> and <code class="literal">NODE22</code>.
							</li><li class="listitem"><p class="simpara">
								Start <code class="literal">NODE11</code> :
							</p><pre class="screen">cd NODE11/bin
./standalone.sh -c standalone-ha.xml -Djboss.node.name=node11 -Djboss.site.name=site1 \
  -Djboss.default.multicast.address=234.56.78.1 -Dremote.cache.host=jdg1 \
  -Djava.net.preferIPv4Stack=true -b <span class="emphasis"><em>PUBLIC_IP_ADDRESS</em></span></pre></li><li class="listitem"><p class="simpara">
								Start <code class="literal">NODE12</code> :
							</p><pre class="screen">cd NODE12/bin
./standalone.sh -c standalone-ha.xml -Djboss.node.name=node12 -Djboss.site.name=site1 \
  -Djboss.default.multicast.address=234.56.78.1 -Dremote.cache.host=jdg1 \
  -Djava.net.preferIPv4Stack=true -b <span class="emphasis"><em>PUBLIC_IP_ADDRESS</em></span></pre><p class="simpara">
								The cluster nodes should be connected. Something like this should be in the log of both NODE11 and NODE12:
							</p><pre class="screen">Received new cluster view for channel keycloak: [node11|1] (2) [node11, node12]</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									The channel name in the log might be different.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Start <code class="literal">NODE21</code> :
							</p><pre class="screen">cd NODE21/bin
./standalone.sh -c standalone-ha.xml -Djboss.node.name=node21 -Djboss.site.name=site2 \
  -Djboss.default.multicast.address=234.56.78.2 -Dremote.cache.host=jdg2 \
  -Djava.net.preferIPv4Stack=true -b <span class="emphasis"><em>PUBLIC_IP_ADDRESS</em></span></pre><p class="simpara">
								It shouldn’t be connected to the cluster with <code class="literal">NODE11</code> and <code class="literal">NODE12</code>, but to separate one:
							</p><pre class="screen">Received new cluster view for channel keycloak: [node21|0] (1) [node21]</pre></li><li class="listitem"><p class="simpara">
								Start <code class="literal">NODE22</code> :
							</p><pre class="screen">cd NODE22/bin
./standalone.sh -c standalone-ha.xml -Djboss.node.name=node22 -Djboss.site.name=site2 \
  -Djboss.default.multicast.address=234.56.78.2 -Dremote.cache.host=jdg2 \
  -Djava.net.preferIPv4Stack=true -b <span class="emphasis"><em>PUBLIC_IP_ADDRESS</em></span></pre><p class="simpara">
								It should be in cluster with <code class="literal">NODE21</code> :
							</p><pre class="screen">Received new cluster view for channel keycloak: [node21|1] (2) [node21, node22]</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									The channel name in the log might be different.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Test:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
										Go to <code class="literal"><a class="link" href="http://node11:8080/auth/">http://node11:8080/auth/</a></code> and create the initial admin user.
									</li><li class="listitem">
										Go to <code class="literal"><a class="link" href="http://node11:8080/auth/admin">http://node11:8080/auth/admin</a></code> and login as admin to admin console.
									</li><li class="listitem">
										Open a second browser and go to any of nodes <code class="literal"><a class="link" href="http://node12:8080/auth/admin">http://node12:8080/auth/admin</a></code> or <code class="literal"><a class="link" href="http://node21:8080/auth/admin">http://node21:8080/auth/admin</a></code> or <code class="literal"><a class="link" href="http://node22:8080/auth/admin">http://node22:8080/auth/admin</a></code>. After login, you should be able to see the same sessions in tab <code class="literal">Sessions</code> of particular user, client or realm on all 4 servers.
									</li><li class="listitem">
										After doing any change in Keycloak admin console (eg. update some user or some realm), the update should be immediately visible on any of 4 nodes as caches should be properly invalidated everywhere.
									</li><li class="listitem"><p class="simpara">
										Check server.logs if needed. After login or logout, the message like this should be on all the nodes <code class="literal">NODEXY/standalone/log/server.log</code> :
									</p><pre class="screen">2017-08-25 17:35:17,737 DEBUG [org.keycloak.models.sessions.infinispan.remotestore.RemoteCacheSessionListener] (Client-Listener-sessions-30012a77422542f5) Received event from remote store.
Event 'CLIENT_CACHE_ENTRY_REMOVED', key '193489e7-e2bc-4069-afe8-f1dfa73084ea', skip 'false'</pre></li></ol></div></li></ol></div></section></section><section class="section" id="administration"><div class="titlepage"><div><div><h3 class="title">3.4.9. Administration of Cross DC deployment</h3></div></div></div><p>
					This section contains some tips and options related to Cross-Datacenter Replication.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							When you run the Red Hat Single Sign-On server inside a data center, it is required that the database referenced in <code class="literal">KeycloakDS</code> datasource is already running and available in that data center. It is also necessary that the JDG server referenced by the <code class="literal">outbound-socket-binding</code>, which is referenced from the Infinispan cache <code class="literal">remote-store</code> element, is already running. Otherwise the Red Hat Single Sign-On server will fail to start.
						</li><li class="listitem">
							Every data center can have more database nodes if you want to support database failover and better reliability. Refer to the documentation of your database and JDBC driver for the details how to set this up on the database side and how the <code class="literal">KeycloakDS</code> datasource on Keycloak side needs to be configured.
						</li><li class="listitem">
							Every datacenter can have more JDG servers running in the cluster. This is useful if you want some failover and better fault tolerance. The HotRod protocol used for communication between JDG servers and Red Hat Single Sign-On servers has a feature that JDG servers will automatically send new topology to the Red Hat Single Sign-On servers about the change in the JDG cluster, so the remote store on Red Hat Single Sign-On side will know to which JDG servers it can connect. Read the JDG and WildFly documentation for more details.
						</li><li class="listitem">
							It is highly recommended that a master JDG server is running in every site before the Red Hat Single Sign-On servers in <span class="strong strong"><strong>any</strong></span> site are started. As in our example, we started both <code class="literal">jdg1</code> and <code class="literal">jdg2</code> first, before all Red Hat Single Sign-On servers. If you still need to run the Red Hat Single Sign-On server and the backup site is offline, it is recommended to manually switch the backup site offline on the JDG servers on your site, as described in <a class="xref" href="#onoffline" title="3.4.10. Bringing sites offline and online">Section 3.4.10, “Bringing sites offline and online”</a>. If you do not manually switch the unavailable site offline, the first startup may fail or they may be some exceptions during startup until the backup site is taken offline automatically due the configured count of failed operations.
						</li></ul></div></section><section class="section" id="onoffline"><div class="titlepage"><div><div><h3 class="title">3.4.10. Bringing sites offline and online</h3></div></div></div><p>
					For example, assume this scenario:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Site <code class="literal">site2</code> is entirely offline from the <code class="literal">site1</code> perspective. This means that all JDG servers on <code class="literal">site2</code> are off <span class="strong strong"><strong>or</strong></span> the network between <code class="literal">site1</code> and <code class="literal">site2</code> is broken.
						</li><li class="listitem">
							You run Red Hat Single Sign-On servers and JDG server <code class="literal">jdg1</code> in site <code class="literal">site1</code>
						</li><li class="listitem">
							Someone logs in on a Red Hat Single Sign-On server on <code class="literal">site1</code>.
						</li><li class="listitem">
							The Red Hat Single Sign-On server from <code class="literal">site1</code> will try to write the session to the remote cache on <code class="literal">jdg1</code> server, which is supposed to backup data to the <code class="literal">jdg2</code> server in the <code class="literal">site2</code>. See <a class="xref" href="#communication" title="3.4.7. Communication details">Section 3.4.7, “Communication details”</a> for more information.
						</li><li class="listitem">
							Server <code class="literal">jdg2</code> is offline or unreachable from <code class="literal">jdg1</code>. So the backup from <code class="literal">jdg1</code> to <code class="literal">jdg2</code> will fail.
						</li><li class="listitem">
							The exception is thrown in <code class="literal">jdg1</code> log and the failure will be propagated from <code class="literal">jdg1</code> server to Red Hat Single Sign-On servers as well because the default <code class="literal">FAIL</code> backup failure policy is configured. See <a class="xref" href="#backupfailure" title="Backup failure policy">Backup failure policy</a> for details around the backup policies.
						</li><li class="listitem">
							The error will happen on Red Hat Single Sign-On side too and user may not be able to finish his login.
						</li></ol></div><p>
					According to your environment, it may be more or less probable that the network between sites is unavailable or temporarily broken (split-brain). In case this happens, it is good that JDG servers on <code class="literal">site1</code> are aware of the fact that JDG servers on <code class="literal">site2</code> are unavailable, so they will stop trying to reach the servers in the <code class="literal">jdg2</code> site and the backup failures won’t happen. This is called <code class="literal">Take site offline</code> .
				</p><div class="formalpara"><p class="title"><strong>Take site offline</strong></p><p>
						There are 2 ways to take the site offline.
					</p></div><p>
					<span class="strong strong"><strong>Manually by admin</strong></span> - Admin can use the <code class="literal">jconsole</code> or other tool and run some JMX operations to manually take the particular site offline. This is useful especially if the outage is planned. With <code class="literal">jconsole</code> or CLI, you can connect to the <code class="literal">jdg1</code> server and take the <code class="literal">site2</code> offline. More details about this are available in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/7.3/html/red_hat_data_grid_user_guide/x_site_replication#taking_a_site_offline">JDG documentation</a>.
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						These steps usually need to be done for all the Red Hat Single Sign-On caches mentioned in <a class="xref" href="#backups" title="3.4.14. SYNC or ASYNC backups">Section 3.4.14, “SYNC or ASYNC backups”</a>.
					</p></div></div><p>
					<span class="strong strong"><strong>Automatically</strong></span> - After some amount of failed backups, the <code class="literal">site2</code> will usually be taken offline automatically. This is done due the configuration of <code class="literal">take-offline</code> element inside the cache configuration as configured in <a class="xref" href="#jdgsetup" title="3.4.8.1. JDG server setup">Section 3.4.8.1, “JDG server setup”</a>.
				</p><pre class="programlisting language-xml">&lt;take-offline min-wait="60000" after-failures="3" /&gt;</pre><p>
					This example shows that the site will be taken offline automatically for the particular single cache if there are at least 3 subsequent failed backups and there is no any successful backup within 60 seconds.
				</p><p>
					Automatically taking a site offline is useful especially if the broken network between sites is unplanned. The disadvantage is that there will be some failed backups until the network outage is detected, which could also mean failures on the application side. For example, there will be failed logins for some users or big login timeouts. Especially if <code class="literal">failure-policy</code> with value <code class="literal">FAIL</code> is used.
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						The tracking of whether a site is offline is tracked separately for every cache.
					</p></div></div><div class="formalpara"><p class="title"><strong>Take site online</strong></p><p>
						Once your network is back and <code class="literal">site1</code> and <code class="literal">site2</code> can talk to each other, you may need to put the site online. This needs to be done manually through JMX or CLI in similar way as taking a site offline. Again, you may need to check all the caches and bring them online.
					</p></div><p>
					Once the sites are put online, it’s usually good to:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Do the <a class="xref" href="#statetransfer" title="3.4.11. State transfer">Section 3.4.11, “State transfer”</a>.
						</li><li class="listitem">
							Manually <a class="xref" href="#clearcache" title="3.4.12. Clear caches">Section 3.4.12, “Clear caches”</a>.
						</li></ul></div></section><section class="section" id="statetransfer"><div class="titlepage"><div><div><h3 class="title">3.4.11. State transfer</h3></div></div></div><p>
					State transfer is a required, manual step. JDG server does not do this automatically, for example during split-brain, it is only the admin who may decide which site has preference and hence if state transfer needs to be done bidirectionally between both sites or just unidirectionally, as in only from <code class="literal">site1</code> to <code class="literal">site2</code>, but not from <code class="literal">site2</code> to <code class="literal">site1</code>.
				</p><p>
					A bidirectional state transfer will ensure that entities which were created <span class="strong strong"><strong>after</strong></span> split-brain on <code class="literal">site1</code> will be transferred to <code class="literal">site2</code>. This is not an issue as they do not yet exist on <code class="literal">site2</code>. Similarly, entities created <span class="strong strong"><strong>after</strong></span> split-brain on <code class="literal">site2</code> will be transferred to <code class="literal">site1</code>. Possibly problematic parts are those entities which exist <span class="strong strong"><strong>before</strong></span> split-brain on both sites and which were updated during split-brain on both sites. When this happens, one of the sites will <span class="strong strong"><strong>win</strong></span> and will overwrite the updates done during split-brain by the second site.
				</p><p>
					Unfortunately, there is no any universal solution to this. Split-brains and network outages are just state, which is usually impossible to be handled 100% correctly with 100% consistent data between sites. In the case of Red Hat Single Sign-On, it typically is not a critical issue. In the worst case, users will need to re-login again to their clients, or have the improper count of loginFailures tracked for brute force protection. See the JDG/JGroups documentation for more tips how to deal with split-brain.
				</p><p>
					The state transfer can be also done on the JDG server side through JMX. The operation name is <code class="literal">pushState</code>. There are few other operations to monitor status, cancel push state, and so on. More info about state transfer is available in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_data_grid/7.3/html/red_hat_data_grid_user_guide/x_site_replication#pushing_state_transfer_to_sites">JDG docs</a>.
				</p></section><section class="section" id="clearcache"><div class="titlepage"><div><div><h3 class="title">3.4.12. Clear caches</h3></div></div></div><p>
					After split-brain it is safe to manually clear caches in the Red Hat Single Sign-On admin console. This is because there might be some data changed in the database on <code class="literal">site1</code> and because of the event, that the cache should be invalidated wasn’t transferred during split-brain to <code class="literal">site2</code>. Hence Red Hat Single Sign-On nodes on <code class="literal">site2</code> may still have some stale data in their caches.
				</p><p>
					To clear the caches, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_administration_guide/#_clear-cache">Clearing Server Caches</a>.
				</p><p>
					When the network is back, it is sufficient to clear the cache just on one Red Hat Single Sign-On node on any random site. The cache invalidation event will be sent to all the other Red Hat Single Sign-On nodes in all sites. However, it needs to be done for all the caches (realms, users, keys). See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_administration_guide/#_clear-cache">Clearing Server Caches</a> for more information.
				</p></section><section class="section" id="tuningcache"><div class="titlepage"><div><div><h3 class="title">3.4.13. Tuning the JDG cache configuration</h3></div></div></div><p>
					This section contains tips and options for configuring your JDG cache.
				</p><div id="backupfailure" class="formalpara"><p class="title"><strong>Backup failure policy</strong></p><p>
						By default, the configuration of backup <code class="literal">failure-policy</code> in the Infinispan cache configuration in the JDG <code class="literal">clustered.xml</code> file is configured as <code class="literal">FAIL</code>. You may change it to <code class="literal">WARN</code> or <code class="literal">IGNORE</code>, as you prefer.
					</p></div><p>
					The difference between <code class="literal">FAIL</code> and <code class="literal">WARN</code> is that when <code class="literal">FAIL</code> is used and the JDG server tries to back data up to the other site and the backup fails then the failure will be propagated back to the caller (the Red Hat Single Sign-On server). The backup might fail because the second site is temporarily unreachable or there is a concurrent transaction which is trying to update same entity. In this case, the Red Hat Single Sign-On server will then retry the operation a few times. However, if the retry fails, then the user might see the error after a longer timeout.
				</p><p>
					When using <code class="literal">WARN</code>, the failed backups are not propagated from the JDG server to the Red Hat Single Sign-On server. The user won’t see the error and the failed backup will be just ignored. There will be a shorter timeout, typically 10 seconds as that’s the default timeout for backup. It can be changed by the attribute <code class="literal">timeout</code> of <code class="literal">backup</code> element. There won’t be retries. There will just be a WARNING message in the JDG server log.
				</p><p>
					The potential issue is, that in some cases, there may be just some a short network outage between sites, where the retry (usage of the <code class="literal">FAIL</code> policy) may help, so with <code class="literal">WARN</code> (without retry), there will be some data inconsistencies across sites. This can also happen if there is an attempt to update the same entity concurrently on both sites.
				</p><p>
					How bad are these inconsistencies? Usually only means that a user will need to re-authenticate.
				</p><p>
					When using the <code class="literal">WARN</code> policy, it may happen that the single-use cache, which is provided by the <code class="literal">actionTokens</code> cache and which handles that particular key is really single use, but may "successfully" write the same key twice. But, for example, the OAuth2 specification <a class="link" href="https://tools.ietf.org/html/rfc6749#section-10.5">mentions</a> that code must be single-use. With the <code class="literal">WARN</code> policy, this may not be strictly guaranteed and the same code could be written twice if there is an attempt to write it concurrently in both sites.
				</p><p>
					If there is a longer network outage or split-brain, then with both <code class="literal">FAIL</code> and <code class="literal">WARN</code>, the other site will be taken offline after some time and failures as described in <a class="xref" href="#onoffline" title="3.4.10. Bringing sites offline and online">Section 3.4.10, “Bringing sites offline and online”</a>. With the default 1 minute timeout, it is usually 1-3 minutes until all the involved caches are taken offline. After that, all the operations will work fine from an end user perspective. You only need to manually restore the site when it is back online as mentioned in <a class="xref" href="#onoffline" title="3.4.10. Bringing sites offline and online">Section 3.4.10, “Bringing sites offline and online”</a>.
				</p><p>
					In summary, if you expect frequent, longer outages between sites and it is acceptable for you to have some data inconsistencies and a not 100% accurate single-use cache, but you never want end-users to see the errors and long timeouts, then switch to <code class="literal">WARN</code>.
				</p><p>
					The difference between <code class="literal">WARN</code> and <code class="literal">IGNORE</code> is, that with <code class="literal">IGNORE</code> warnings are not written in the JDG log. See more details in the Infinispan documentation.
				</p><div class="formalpara"><p class="title"><strong>Lock acquisition timeout</strong></p><p>
						The default configuration is using transaction in NON_DURABLE_XA mode with acquire timeout 0. This means that transaction will fail-fast if there is another transaction in progress for the same key.
					</p></div><p>
					The reason to switch this to 0 instead of default 10 seconds was to avoid possible deadlock issues. With Red Hat Single Sign-On, it can happen that the same entity (typically session entity or loginFailure) is updated concurrently from both sites. This can cause deadlock under some circumstances, which will cause the transaction to be blocked for 10 seconds. See <a class="link" href="https://issues.jboss.org/browse/JDG-1318">this JIRA report</a> for details.
				</p><p>
					With timeout 0, the transaction will immediately fail and then will be retried from Red Hat Single Sign-On if backup <code class="literal">failure-policy</code> with the value <code class="literal">FAIL</code> is configured. As long as the second concurrent transaction is finished, the retry will usually be successful and the entity will have applied updates from both concurrent transactions.
				</p><p>
					We see very good consistency and results for concurrent transaction with this configuration, and it is recommended to keep it.
				</p><p>
					The only (non-functional) problem is the exception in the JDG server log, which happens every time when the lock is not immediately available.
				</p></section><section class="section" id="backups"><div class="titlepage"><div><div><h3 class="title">3.4.14. SYNC or ASYNC backups</h3></div></div></div><p>
					An important part of the <code class="literal">backup</code> element is the <code class="literal">strategy</code> attribute. You must decide whether it needs to be <code class="literal">SYNC</code> or <code class="literal">ASYNC</code>. We have 7 caches which might be Cross-Datacenter Replication aware, and these can be configured in 3 different modes regarding cross-dc:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							SYNC backup
						</li><li class="listitem">
							ASYNC backup
						</li><li class="listitem">
							No backup at all
						</li></ol></div><p>
					If the <code class="literal">SYNC</code> backup is used, then the backup is synchronous and operation is considered finished on the caller (Red Hat Single Sign-On server) side once the backup is processed on the second site. This has worse performance than <code class="literal">ASYNC</code>, but on the other hand, you are sure that subsequent reads of the particular entity, such as user session, on <code class="literal">site2</code> will see the updates from <code class="literal">site1</code>. Also, it is needed if you want data consistency. As with <code class="literal">ASYNC</code> the caller is not notified at all if backup to the other site failed.
				</p><p>
					For some caches, it is even possible to not backup at all and completely skip writing data to the JDG server. To set this up, do not use the <code class="literal">remote-store</code> element for the particular cache on the Red Hat Single Sign-On side (file <code class="literal">KEYCLOAK_HOME/standalone/configuration/standalone-ha.xml</code>) and then the particular <code class="literal">replicated-cache</code> element is also not needed on the JDG server side.
				</p><p>
					By default, all 7 caches are configured with <code class="literal">SYNC</code> backup, which is the safest option. Here are a few things to consider:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							If you are using active/passive mode (all Red Hat Single Sign-On servers are in single site <code class="literal">site1</code> and the JDG server in <code class="literal">site2</code> is used purely as backup. See <a class="xref" href="#modes" title="3.4.4. Modes">Section 3.4.4, “Modes”</a> for more details), then it is usually fine to use <code class="literal">ASYNC</code> strategy for all the caches to save the performance.
						</li><li class="listitem">
							The <code class="literal">work</code> cache is used mainly to send some messages, such as cache invalidation events, to the other site. It is also used to ensure that some special events, such as userStorage synchronizations, happen only on single site. It is recommended to keep this set to <code class="literal">SYNC</code>.
						</li><li class="listitem">
							The <code class="literal">actionTokens</code> cache is used as single-use cache to track that some tokens/tickets were used just once. For example action tokens or OAuth2 codes. It is possible to set this to <code class="literal">ASYNC</code> to slightly improved performance, but then it is not guaranteed that particular ticket is really single-use. For example, if there is concurrent request for same ticket in both sites, then it is possible that both requests will be successful with the <code class="literal">ASYNC</code> strategy. So what you set here will depend on whether you prefer better security (<code class="literal">SYNC</code> strategy) or better performance (<code class="literal">ASYNC</code> strategy).
						</li><li class="listitem">
							The <code class="literal">loginFailures</code> cache may be used in any of the 3 modes. If there is no backup at all, it means that count of login failures for a user will be counted separately for every site (See <a class="xref" href="#cache" title="3.4.6. Infinispan caches">Section 3.4.6, “Infinispan caches”</a> for details). This has some security implications, however it has some performance advantages. Also it mitigates the possible risk of denial of service (DoS) attacks. For example, if an attacker simulates 1000 concurrent requests using the username and password of the user on both sites, it will mean lots of messages being passed between the sites, which may result in network congestion. The <code class="literal">ASYNC</code> strategy might be even worse as the attacker requests won’t be blocked by waiting for the backup to the other site, resulting in potentially even more congested network traffic. The count of login failures also will not be accurate with the <code class="literal">ASYNC</code> strategy.
						</li></ul></div><p>
					For the environments with slower network between data centers and probability of DoS, it is recommended to not backup the <code class="literal">loginFailures</code> cache at all.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							It is recommended to keep the <code class="literal">sessions</code> and <code class="literal">clientSessions</code> caches in <code class="literal">SYNC</code>. Switching them to <code class="literal">ASYNC</code> is possible only if you are sure that user requests and backchannel requests (requests from client applications to Red Hat Single Sign-On as described in <a class="xref" href="#requestprocessing" title="3.4.3. Request processing">Section 3.4.3, “Request processing”</a>) will be always processed on same site. This is true, for example, if:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									You use active/passive mode as described <a class="xref" href="#modes" title="3.4.4. Modes">Section 3.4.4, “Modes”</a>.
								</li><li class="listitem">
									All your client applications are using the Red Hat Single Sign-On <a class="link" href="https://www.keycloak.org/docs/latest/securing_apps/index.html#_javascript_adapter">JavaScript Adapter</a>. The JavaScript adapter sends the backchannel requests within the browser and hence they participate on the browser sticky session and will end on same cluster node (hence on same site) as the other browser requests of this user.
								</li><li class="listitem"><p class="simpara">
									Your load balancer is able to serve the requests based on client IP address (location) and the client applications are deployed on both sites.
								</p><p class="simpara">
									For example you have 2 sites LON and NYC. As long as your applications are deployed in both LON and NYC sites too, you can ensure that all the user requests from London users will be redirected to the applications in LON site and also to the Red Hat Single Sign-On servers in LON site. Backchannel requests from the LON site client deployments will end on Red Hat Single Sign-On servers in LON site too. On the other hand, for the American users, all the Red Hat Single Sign-On requests, application requests and backchannel requests will be processed on NYC site.
								</p></li></ul></div></li><li class="listitem">
							For <code class="literal">offlineSessions</code> and <code class="literal">offlineClientSessions</code> it is similar, with the difference that you even don’t need to backup them at all if you never plan to use offline tokens for any of your client applications.
						</li></ul></div><p>
					Generally, if you are in doubt and performance is not a blocker for you, it’s safer to keep the caches in <code class="literal">SYNC</code> strategy.
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						Regarding the switch to SYNC/ASYNC backup, make sure that you edit the <code class="literal">strategy</code> attribute of the <code class="literal">backup</code> element. For example like this:
					</p></div></div><pre class="programlisting language-xml">&lt;backup site="site2" failure-policy="FAIL" strategy="ASYNC" enabled="true"&gt;</pre><p>
					Note the <code class="literal">mode</code> attribute of cache-configuration element.
				</p></section><section class="section" id="troubleshooting"><div class="titlepage"><div><div><h3 class="title">3.4.15. Troubleshooting</h3></div></div></div><p>
					The following tips are intended to assist you should you need to troubleshoot:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							It is recommended to go through the <a class="xref" href="#setup" title="3.4.8. Basic setup">Section 3.4.8, “Basic setup”</a> and have this one working first, so that you have some understanding of how things work. It is also wise to read this entire document to have some understanding of things.
						</li><li class="listitem">
							Check in jconsole cluster status (GMS) and the JGroups status (RELAY) of JDG as described in <a class="xref" href="#jdgsetup" title="3.4.8.1. JDG server setup">Section 3.4.8.1, “JDG server setup”</a>. If things do not look as expected, then the issue is likely in the setup of JDG servers.
						</li><li class="listitem"><p class="simpara">
							For the Red Hat Single Sign-On servers, you should see a message like this during the server startup:
						</p><pre class="screen">18:09:30,156 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (ServerService Thread Pool -- 54)
Node name: node11, Site name: site1</pre><p class="simpara">
							Check that the site name and the node name looks as expected during the startup of Red Hat Single Sign-On server.
						</p></li><li class="listitem">
							Check that Red Hat Single Sign-On servers are in cluster as expected, including that only the Red Hat Single Sign-On servers from the same data center are in cluster with each other. This can be also checked in JConsole through the GMS view. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_installation_and_configuration_guide/#troubleshooting">cluster troubleshooting</a> for additional details.
						</li><li class="listitem"><p class="simpara">
							If there are exceptions during startup of Red Hat Single Sign-On server like this:
						</p><pre class="screen">17:33:58,605 ERROR [org.infinispan.client.hotrod.impl.operations.RetryOnFailureOperation] (ServerService Thread Pool -- 59) ISPN004007: Exception encountered. Retry 10 out of 10: org.infinispan.client.hotrod.exceptions.TransportException:: Could not fetch transport
...
Caused by: org.infinispan.client.hotrod.exceptions.TransportException:: Could not connect to server: 127.0.0.1:12232
	at org.infinispan.client.hotrod.impl.transport.tcp.TcpTransport.&lt;init&gt;(TcpTransport.java:82)</pre><p class="simpara">
							it usually means that Red Hat Single Sign-On server is not able to reach the JDG server in his own datacenter. Make sure that firewall is set as expected and JDG server is possible to connect.
						</p></li><li class="listitem"><p class="simpara">
							If there are exceptions during startup of Red Hat Single Sign-On server like this:
						</p><pre class="screen">16:44:18,321 WARN  [org.infinispan.client.hotrod.impl.protocol.Codec21] (ServerService Thread Pool -- 57) ISPN004005: Error received from the server: javax.transaction.RollbackException: ARJUNA016053: Could not commit transaction.
 ...</pre><p class="simpara">
							then check the log of corresponding JDG server of your site and check if has failed to backup to the other site. If the backup site is unavailable, then it is recommended to switch it offline, so that JDG server won’t try to backup to the offline site causing the operations to pass successfully on Red Hat Single Sign-On server side as well. See <a class="xref" href="#administration" title="3.4.9. Administration of Cross DC deployment">Section 3.4.9, “Administration of Cross DC deployment”</a> for more information.
						</p></li><li class="listitem">
							Check the Infinispan statistics, which are available through JMX. For example, try to login and then see if the new session was successfully written to both JDG servers and is available in the <code class="literal">sessions</code> cache there. This can be done indirectly by checking the count of elements in the <code class="literal">sessions</code> cache for the MBean <code class="literal">jboss.datagrid-infinispan:type=Cache,name="sessions(repl_sync)",manager="clustered",component=Statistics</code> and attribute <code class="literal">numberOfEntries</code>. After login, there should be one more entry for <code class="literal">numberOfEntries</code> on both JDG servers on both sites.
						</li><li class="listitem">
							Enable DEBUG logging as described <a class="xref" href="#serversetup" title="3.4.8.2. Red Hat Single Sign-On servers setup">Section 3.4.8.2, “Red Hat Single Sign-On servers setup”</a>. For example, if you log in and you think that the new session is not available on the second site, it’s good to check the Red Hat Single Sign-On server logs and check that listeners were triggered as described in the <a class="xref" href="#serversetup" title="3.4.8.2. Red Hat Single Sign-On servers setup">Section 3.4.8.2, “Red Hat Single Sign-On servers setup”</a>. If you do not know and want to ask on keycloak-user mailing list, it is helpful to send the log files from Red Hat Single Sign-On servers on both datacenters in the email. Either add the log snippets to the mails or put the logs somewhere and reference them in the email.
						</li><li class="listitem">
							If you updated the entity, such as <code class="literal">user</code>, on Red Hat Single Sign-On server on <code class="literal">site1</code> and you do not see that entity updated on the Red Hat Single Sign-On server on <code class="literal">site2</code>, then the issue can be either in the replication of the synchronous database itself or that Red Hat Single Sign-On caches are not properly invalidated. You may try to temporarily disable the Red Hat Single Sign-On caches as described <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_installation_and_configuration_guide/#disabling-caching">here</a> to nail down if the issue is at the database replication level. Also it may help to manually connect to the database and check if data are updated as expected. This is specific to every database, so you will need to consult the documentation for your database.
						</li><li class="listitem"><p class="simpara">
							Sometimes you may see the exceptions related to locks like this in JDG server log:
						</p><pre class="screen">(HotRodServerHandler-6-35) ISPN000136: Error executing command ReplaceCommand,
writing keys [[B0x033E243034396234..[39]]: org.infinispan.util.concurrent.TimeoutException: ISPN000299: Unable to acquire lock after
0 milliseconds for key [B0x033E243034396234..[39] and requestor GlobalTx:jdg1:4353. Lock is held by GlobalTx:jdg1:4352</pre><p class="simpara">
							Those exceptions are not necessarily an issue. They may happen anytime when a concurrent edit of the same entity is triggered on both DCs. This is common in a deployment. Usually the Red Hat Single Sign-On server is notified about the failed operation and will retry it, so from the user’s point of view, there is usually not any issue.
						</p></li><li class="listitem"><p class="simpara">
							If there are exceptions during startup of Red Hat Single Sign-On server, like this:
						</p><pre class="screen">16:44:18,321 WARN  [org.infinispan.client.hotrod.impl.protocol.Codec21] (ServerService Thread Pool -- 55) ISPN004005: Error received from the server: java.lang.SecurityException: ISPN000287: Unauthorized access: subject 'Subject with principal(s): []' lacks 'READ' permission
 ...</pre><p class="simpara">
							These log entries are the result of Red Hat Single Sign-On automatically detecting whether authentication is required on JDG and mean that authentication is necessary. At this point you will notice that either the server starts successfully and you can safely ignore these or that the server fails to start. If the server fails to start, ensure that JDG has been configured properly for authentication as described in <a class="xref" href="#jdgsetup" title="3.4.8.1. JDG server setup">Section 3.4.8.1, “JDG server setup”</a>. To prevent this log entry from being included, you can force authentication by setting <code class="literal">remoteStoreSecurityEnabled</code> property to <code class="literal">true</code> in <code class="literal">spi=connectionsInfinispan/provider=default</code> configuration:
						</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:keycloak-server:1.1"&gt;
    ...
    &lt;spi name="connectionsInfinispan"&gt;
        ...
        &lt;provider name="default" enabled="true"&gt;
            &lt;properties&gt;
                ...
                &lt;property name="remoteStoreSecurityEnabled" value="true"/&gt;
            &lt;/properties&gt;
        &lt;/provider&gt;
    &lt;/spi&gt;</pre></li><li class="listitem"><p class="simpara">
							If you try to authenticate with Red Hat Single Sign-On to your application, but authentication fails with an infinite number of redirects in your browser and you see the errors like this in the Red Hat Single Sign-On server log:
						</p><pre class="screen">2017-11-27 14:50:31,587 WARN  [org.keycloak.events] (default task-17) type=LOGIN_ERROR, realmId=master, clientId=null, userId=null, ipAddress=aa.bb.cc.dd, error=expired_code, restart_after_timeout=true</pre><p class="simpara">
							it probably means that your load balancer needs to be set to support sticky sessions. Make sure that the provided route name used during startup of Red Hat Single Sign-On server (Property <code class="literal">jboss.node.name</code>) contains the correct name used by the load balancer server to identify the current server.
						</p></li><li class="listitem"><p class="simpara">
							If the JDG <code class="literal">work</code> cache grows indefinitely, you may be experiencing <a class="link" href="https://issues.jboss.org/browse/JDG-987">this JDG issue</a>, which is caused by cache items not being properly expired. In that case, update the cache declaration with an empty <code class="literal">&lt;expiration /&gt;</code> tag like this:
						</p><pre class="programlisting language-xml">    &lt;replicated-cache name="work" configuration="sessions-cfg"&gt;
        &lt;expiration /&gt;
    &lt;/replicated-cache&gt;</pre></li><li class="listitem"><p class="simpara">
							If you see Warnings in the JDG server log like:
						</p><pre class="screen">18:06:19,687 WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-7-12) ISPN006011: Operation 'PUT_IF_ABSENT' forced to
  return previous value should be used on transactional caches, otherwise data inconsistency issues could arise under failure situations
18:06:19,700 WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-7-10) ISPN006010: Conditional operation 'REPLACE_IF_UNMODIFIED' should
  be used with transactional caches, otherwise data inconsistency issues could arise under failure situations</pre><p class="simpara">
							you can just ignore them. To avoid the warning, the caches on JDG server side could be changed to transactional caches, but this is not recommended as it can cause some other issues caused by the bug <a class="link" href="https://issues.jboss.org/browse/ISPN-9323">https://issues.jboss.org/browse/ISPN-9323</a>. So for now, the warnings just need to be ignored.
						</p></li><li class="listitem"><p class="simpara">
							If you see errors in the JDG server log like:
						</p><pre class="screen">12:08:32,921 ERROR [org.infinispan.server.hotrod.CacheDecodeContext] (HotRod-ServerWorker-7-11) ISPN005003: Exception reported: org.infinispan.server.hotrod.InvalidMagicIdException: Error reading magic byte or message id: 7
	at org.infinispan.server.hotrod.HotRodDecoder.readHeader(HotRodDecoder.java:184)
	at org.infinispan.server.hotrod.HotRodDecoder.decodeHeader(HotRodDecoder.java:133)
	at org.infinispan.server.hotrod.HotRodDecoder.decode(HotRodDecoder.java:92)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:411)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248)</pre><p class="simpara">
							and you see some similar errors in the Red Hat Single Sign-On log, it can indicate that there are incompatible versions of the HotRod protocol being used. This is likely happen when you try to use Red Hat Single Sign-On with the JDG 7.2 server or an old version of the Infinispan server. It will help if you add the <code class="literal">protocolVersion</code> property as an additional property to the <code class="literal">remote-store</code> element in the Red Hat Single Sign-On configuration file. For example:
						</p><pre class="programlisting language-xml">&lt;property name="protocolVersion"&gt;2.6&lt;/property&gt;</pre></li></ul></div></section></section></section><section class="chapter" id="manage_subsystem_configuration"><div class="titlepage"><div><div><h1 class="title">Chapter 4. Manage Subsystem Configuration</h1></div></div></div><p>
			Low-level configuration of Red Hat Single Sign-On is done by editing the <code class="literal">standalone.xml</code>, <code class="literal">standalone-ha.xml</code>, or <code class="literal">domain.xml</code> file in your distribution. The location of this file depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>.
		</p><p>
			While there are endless settings you can configure here, this section will focus on configuration of the <span class="emphasis"><em>keycloak-server</em></span> subsystem. No matter which configuration file you are using, configuration of the <span class="emphasis"><em>keycloak-server</em></span> subsystem is the same.
		</p><p>
			The keycloak-server subsystem is typically declared toward the end of the file like this:
		</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:keycloak-server:1.1"&gt;
   &lt;web-context&gt;auth&lt;/web-context&gt;
   ...
&lt;/subsystem&gt;</pre><p>
			Note that anything changed in this subsystem will not take effect until the server is rebooted.
		</p><section class="section" id="config_spi_providers"><div class="titlepage"><div><div><h2 class="title">4.1. Configure SPI Providers</h2></div></div></div><p>
				The specifics of each configuration setting is discussed elsewhere in context with that setting. However, it is useful to understand the format used to declare settings on SPI providers.
			</p><p>
				Red Hat Single Sign-On is a highly modular system that allows great flexibility. There are more than 50 service provider interfaces (SPIs), and you are allowed to swap out implementations of each SPI. An implementation of an SPI is known as a <span class="emphasis"><em>provider</em></span>.
			</p><p>
				All elements in an SPI declaration are optional, but a full SPI declaration looks like this:
			</p><pre class="programlisting language-xml">&lt;spi name="myspi"&gt;
    &lt;default-provider&gt;myprovider&lt;/default-provider&gt;
    &lt;provider name="myprovider" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property name="foo" value="bar"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
    &lt;provider name="mysecondprovider" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property name="foo" value="foo"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
&lt;/spi&gt;</pre><p>
				Here we have two providers defined for the SPI <code class="literal">myspi</code>. The <code class="literal">default-provider</code> is listed as <code class="literal">myprovider</code>. However it is up to the SPI to decide how it will treat this setting. Some SPIs allow more than one provider and some do not. So <code class="literal">default-provider</code> can help the SPI to choose.
			</p><p>
				Also notice that each provider defines its own set of configuration properties. The fact that both providers above have a property called <code class="literal">foo</code> is just a coincidence.
			</p><p>
				The type of each property value is interpreted by the provider. However, there is one exception. Consider the <code class="literal">jpa</code> provider for the <code class="literal">eventsStore</code> SPI:
			</p><pre class="programlisting language-xml">&lt;spi name="eventsStore"&gt;
    &lt;provider name="jpa" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property name="exclude-events" value="[&amp;quot;EVENT1&amp;quot;,
                                                    &amp;quot;EVENT2&amp;quot;]"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
&lt;/spi&gt;</pre><p>
				We see that the value begins and ends with square brackets. That means that the value will be passed to the provider as a list. In this example, the system will pass the provider a list with two element values <span class="emphasis"><em>EVENT1</em></span> and <span class="emphasis"><em>EVENT2</em></span>. To add more values to the list, just separate each list element with a comma. Unfortunately, you do need to escape the quotes surrounding each list element with <code class="literal">&amp;quot;</code>.
			</p></section><section class="section" id="start_cli"><div class="titlepage"><div><div><h2 class="title">4.2. Start the JBoss EAP CLI</h2></div></div></div><p>
				Besides editing the configuration by hand, you also have the option of changing the configuration by issuing commands via the <span class="emphasis"><em>jboss-cli</em></span> tool. CLI allows you to configure servers locally or remotely. And it is especially useful when combined with scripting.
			</p><p>
				To start the JBoss EAP CLI, you need to run <code class="literal">jboss-cli</code>.
			</p><div class="formalpara"><p class="title"><strong>Linux/Unix</strong></p><p>
					
<pre class="screen">$ .../bin/jboss-cli.sh</pre>
				</p></div><div class="formalpara"><p class="title"><strong>Windows</strong></p><p>
					
<pre class="screen">&gt; ...\bin\jboss-cli.bat</pre>
				</p></div><p>
				This will bring you to a prompt like this:
			</p><div class="formalpara"><p class="title"><strong>Prompt</strong></p><p>
					
<pre class="screen">[disconnected /]</pre>
				</p></div><p>
				If you wish to execute commands on a running server, you will first execute the <code class="literal">connect</code> command.
			</p><div class="formalpara"><p class="title"><strong>connect</strong></p><p>
					
<pre class="screen">[disconnected /] connect
connect
[standalone@localhost:9990 /]</pre>
				</p></div><p>
				You may be thinking to yourself, "I didn’t enter in any username or password!". If you run <code class="literal">jboss-cli</code> on the same machine as your running standalone server or domain controller and your account has appropriate file permissions, you do not have to setup or enter in an admin username and password. See the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/"><span class="emphasis"><em>JBoss EAP Configuration Guide</em></span></a> for more details on how to make things more secure if you are uncomfortable with that setup.
			</p></section><section class="section" id="cli_embedded_mode"><div class="titlepage"><div><div><h2 class="title">4.3. CLI Embedded Mode</h2></div></div></div><p>
				If you do happen to be on the same machine as your standalone server and you want to issue commands while the server is not active, you can embed the server into CLI and make changes in a special mode that disallows incoming requests. To do this, first execute the <code class="literal">embed-server</code> command with the config file you wish to change.
			</p><div class="formalpara"><p class="title"><strong>embed-server</strong></p><p>
					
<pre class="screen">[disconnected /] embed-server --server-config=standalone.xml
[standalone@embedded /]</pre>
				</p></div></section><section class="section" id="cli_gui_mode"><div class="titlepage"><div><div><h2 class="title">4.4. CLI GUI Mode</h2></div></div></div><p>
				The CLI can also run in GUI mode. GUI mode launches a Swing application that allows you to graphically view and edit the entire management model of a <span class="emphasis"><em>running</em></span> server. GUI mode is especially useful when you need help formatting your CLI commands and learning about the options available. The GUI can also retrieve server logs from a local or remote server.
			</p><div class="formalpara"><p class="title"><strong>Start in GUI mode</strong></p><p>
					
<pre class="screen">$ .../bin/jboss-cli.sh --gui</pre>
				</p></div><p>
				<span class="emphasis"><em>Note: to connect to a remote server, you pass the <code class="literal">--connect</code> option as well. Use the --help option for more details.</em></span>
			</p><p>
				After launching GUI mode, you will probably want to scroll down to find the node, <code class="literal">subsystem=keycloak-server</code>. If you right-click on the node and click <code class="literal">Explore subsystem=keycloak-server</code>, you will get a new tab that shows only the keycloak-server subsystem.
			</p><p>
				<span class="inlinemediaobject"><img src="images/cli-gui.png" alt="cli gui"/></span>
			</p></section><section class="section" id="cli_scripting"><div class="titlepage"><div><div><h2 class="title">4.5. CLI Scripting</h2></div></div></div><p>
				The CLI has extensive scripting capabilities. A script is just a text file with CLI commands in it. Consider a simple script that turns off theme and template caching.
			</p><div class="formalpara"><p class="title"><strong>turn-off-caching.cli</strong></p><p>
					
<pre class="screen">/subsystem=keycloak-server/theme=defaults/:write-attribute(name=cacheThemes,value=false)
/subsystem=keycloak-server/theme=defaults/:write-attribute(name=cacheTemplates,value=false)</pre>
				</p></div><p>
				To execute the script, I can follow the <code class="literal">Scripts</code> menu in CLI GUI, or execute the script from the command line as follows:
			</p><pre class="screen">$ .../bin/jboss-cli.sh --file=turn-off-caching.cli</pre></section><section class="section" id="cli_recipes"><div class="titlepage"><div><div><h2 class="title">4.6. CLI Recipes</h2></div></div></div><p>
				Here are some configuration tasks and how to perform them with CLI commands. Note that in all but the first example, we use the wildcard path <code class="literal">**</code> to mean you should substitute or the path to the keycloak-server subsystem.
			</p><p>
				For standalone, this just means:
			</p><p>
				<code class="literal">**</code> = <code class="literal">/subsystem=keycloak-server</code>
			</p><p>
				For domain mode, this would mean something like:
			</p><p>
				<code class="literal">**</code> = <code class="literal">/profile=auth-server-clustered/subsystem=keycloak-server</code>
			</p><section class="section" id="change_the_web_context_of_the_server"><div class="titlepage"><div><div><h3 class="title">4.6.1. Change the web context of the server</h3></div></div></div><pre class="screen">/subsystem=keycloak-server/:write-attribute(name=web-context,value=myContext)</pre></section><section class="section" id="set_the_global_default_theme"><div class="titlepage"><div><div><h3 class="title">4.6.2. Set the global default theme</h3></div></div></div><pre class="screen">**/theme=defaults/:write-attribute(name=default,value=myTheme)</pre></section><section class="section" id="add_a_new_spi_and_a_provider"><div class="titlepage"><div><div><h3 class="title">4.6.3. Add a new SPI and a provider</h3></div></div></div><pre class="screen">**/spi=mySPI/:add
**/spi=mySPI/provider=myProvider/:add(enabled=true)</pre></section><section class="section" id="disable_a_provider"><div class="titlepage"><div><div><h3 class="title">4.6.4. Disable a provider</h3></div></div></div><pre class="screen">**/spi=mySPI/provider=myProvider/:write-attribute(name=enabled,value=false)</pre></section><section class="section" id="change_the_default_provider_for_an_spi"><div class="titlepage"><div><div><h3 class="title">4.6.5. Change the default provider for an SPI</h3></div></div></div><pre class="screen">**/spi=mySPI/:write-attribute(name=default-provider,value=myProvider)</pre></section><section class="section" id="configure_the_dblock_spi"><div class="titlepage"><div><div><h3 class="title">4.6.6. Configure the dblock SPI</h3></div></div></div><pre class="screen">**/spi=dblock/:add(default-provider=jpa)
**/spi=dblock/provider=jpa/:add(properties={lockWaitTimeout =&gt; "900"},enabled=true)</pre></section><section class="section" id="add_or_change_a_single_property_value_for_a_provider"><div class="titlepage"><div><div><h3 class="title">4.6.7. Add or change a single property value for a provider</h3></div></div></div><pre class="screen">**/spi=dblock/provider=jpa/:map-put(name=properties,key=lockWaitTimeout,value=3)</pre></section><section class="section" id="remove_a_single_property_from_a_provider"><div class="titlepage"><div><div><h3 class="title">4.6.8. Remove a single property from a provider</h3></div></div></div><pre class="screen">**/spi=dblock/provider=jpa/:map-remove(name=properties,key=lockRecheckTime)</pre></section><section class="section" id="set_values_on_a_provider_property_of_type_literal_list_literal"><div class="titlepage"><div><div><h3 class="title">4.6.9. Set values on a provider property of type <code class="literal">List</code></h3></div></div></div><pre class="screen">**/spi=eventsStore/provider=jpa/:map-put(name=properties,key=exclude-events,value=[EVENT1,EVENT2])</pre></section></section></section><section class="chapter" id="profiles"><div class="titlepage"><div><div><h1 class="title">Chapter 5. Profiles</h1></div></div></div><p>
			There are features in Red Hat Single Sign-On that are not enabled by default, these include features that are not fully supported. In addition there are some features that are enabled by default, but that can be disabled.
		</p><p>
			The features that can be enabled and disabled are:
		</p><div class="informaltable"><table class="gt-4-cols lt-7-rows"><colgroup><col style="width: 25%; " class="col_1"/><col style="width: 25%; " class="col_2"/><col style="width: 25%; " class="col_3"/><col style="width: 25%; " class="col_4"/></colgroup><thead><tr><th align="left" valign="top" id="idm140154418103536" scope="col">Name</th><th align="left" valign="top" id="idm140154418102448" scope="col">Description</th><th align="left" valign="top" id="idm140154418101360" scope="col">Enabled by default</th><th align="left" valign="top" id="idm140154418100272" scope="col">Support level</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							account_api
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Account Management REST API
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Preview
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							admin_fine_grained_authz
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Fine-Grained Admin Permissions
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Preview
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							authz_drools_policy
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Drools Policy for Authorization Services
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Preview
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							docker
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Docker Registry protocol
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Supported
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							impersonation
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Ability for admins to impersonate users
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							Yes
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Supported
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							openshift_integration
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Extension to enable securing OpenShift
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Preview
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							scripts
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Write custom authenticators using JavaScript
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Preview
						</p>
						</td></tr><tr><td align="left" valign="top" headers="idm140154418103536">
						<p>
							token_exchange
						</p>
						</td><td align="left" valign="top" headers="idm140154418102448">
						<p>
							Token Exchange Service
						</p>
						</td><td align="left" valign="top" headers="idm140154418101360">
						<p>
							No
						</p>
						</td><td align="left" valign="top" headers="idm140154418100272">
						<p>
							Preview
						</p>
						</td></tr></tbody></table></div><p>
			To enable all preview features start the server with:
		</p><pre class="screen">bin/standalone.sh|bat -Dkeycloak.profile=preview</pre><p>
			You can set this permanently by creating the file <code class="literal">standalone/configuration/profile.properties</code> (or <code class="literal">domain/servers/server-one/configuration/profile.properties</code> for <code class="literal">server-one</code> in domain mode). Add the following to the file:
		</p><pre class="screen">profile=preview</pre><p>
			To enable a specific feature start the server with:
		</p><pre class="screen">bin/standalone.sh|bat -Dkeycloak.profile.feature.&lt;feature name&gt;=enabled</pre><p>
			For example to enable Docker use <code class="literal">-Dkeycloak.profile.feature.docker=enabled</code>.
		</p><p>
			You can set this permanently in the <code class="literal">profile.properties</code> file by adding:
		</p><pre class="screen">feature.docker=enabled</pre><p>
			To disable a specific feature start the server with:
		</p><pre class="screen">bin/standalone.sh|bat -Dkeycloak.profile.feature.&lt;feature name&gt;=disabled</pre><p>
			For example to disable Impersonation use <code class="literal">-Dkeycloak.profile.feature.impersonation=disabled</code>.
		</p><p>
			You can set this permanently in the <code class="literal">profile.properties</code> file by adding:
		</p><pre class="screen">feature.impersonation=disabled</pre></section><section class="chapter" id="database-1"><div class="titlepage"><div><div><h1 class="title">Chapter 6. Relational Database Setup</h1></div></div></div><p>
			Red Hat Single Sign-On comes with its own embedded Java-based relational database called H2. This is the default database that Red Hat Single Sign-On will use to persist data and really only exists so that you can run the authentication server out of the box. We highly recommend that you replace it with a more production ready external database. The H2 database is not very viable in high concurrency situations and should not be used in a cluster either. The purpose of this chapter is to show you how to connect Red Hat Single Sign-On to a more mature database.
		</p><p>
			Red Hat Single Sign-On uses two layered technologies to persist its relational data. The bottom layered technology is JDBC. JDBC is a Java API that is used to connect to a RDBMS. There are different JDBC drivers per database type that are provided by your database vendor. This chapter discusses how to configure Red Hat Single Sign-On to use one of these vendor-specific drivers.
		</p><p>
			The top layered technology for persistence is Hibernate JPA. This is a object to relational mapping API that maps Java Objects to relational data. Most deployments of Red Hat Single Sign-On will never have to touch the configuration aspects of Hibernate, but we will discuss how that is done if you run into that rare circumstance.
		</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				Datasource configuration is covered much more thoroughly in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#datasource_management">the datasource configuration chapter</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
			</p></div></div><section class="section" id="rdbms-setup-checklist"><div class="titlepage"><div><div><h2 class="title">6.1. RDBMS Setup Checklist</h2></div></div></div><p>
				These are the steps you will need to perform to get an RDBMS configured for Red Hat Single Sign-On.
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Locate and download a JDBC driver for your database
					</li><li class="listitem">
						Package the driver JAR into a module and install this module into the server
					</li><li class="listitem">
						Declare the JDBC driver in the configuration profile of the server
					</li><li class="listitem">
						Modify the datasource configuration to use your database’s JDBC driver
					</li><li class="listitem">
						Modify the datasource configuration to define the connection parameters to your database
					</li></ol></div><p>
				This chapter will use PostgresSQL for all its examples. Other databases follow the same steps for installation.
			</p></section><section class="section" id="package_the_jdbc_driver"><div class="titlepage"><div><div><h2 class="title">6.2. Package the JDBC Driver</h2></div></div></div><p>
				Find and download the JDBC driver JAR for your RDBMS. Before you can use this driver, you must package it up into a module and install it into the server. Modules define JARs that are loaded into the Red Hat Single Sign-On classpath and the dependencies those JARs have on other modules. They are pretty simple to set up.
			</p><p>
				Within the <span class="emphasis"><em>…​/modules/</em></span> directory of your Red Hat Single Sign-On distribution, you need to create a directory structure to hold your module definition. The convention is use the Java package name of the JDBC driver for the name of the directory structure. For PostgreSQL, create the directory <span class="emphasis"><em>org/postgresql/main</em></span>. Copy your database driver JAR into this directory and create an empty <span class="emphasis"><em>module.xml</em></span> file within it too.
			</p><div class="formalpara"><p class="title"><strong>Module Directory</strong></p><p>
					<span class="inlinemediaobject"><img src="images/rhsso-images/db-module.png" alt="db module"/></span>
				</p></div><p>
				After you have done this, open up the <span class="emphasis"><em>module.xml</em></span> file and create the following XML:
			</p><div class="formalpara"><p class="title"><strong>Module XML</strong></p><p>
					
<pre class="programlisting language-xml">&lt;?xml version="1.0" ?&gt;
&lt;module xmlns="urn:jboss:module:1.3" name="org.postgresql"&gt;

    &lt;resources&gt;
        &lt;resource-root path="postgresql-9.4.1212.jar"/&gt;
    &lt;/resources&gt;

    &lt;dependencies&gt;
        &lt;module name="javax.api"/&gt;
        &lt;module name="javax.transaction.api"/&gt;
    &lt;/dependencies&gt;
&lt;/module&gt;</pre>
				</p></div><p>
				The module name should match the directory structure of your module. So, <span class="emphasis"><em>org/postgresql</em></span> maps to <code class="literal">org.postgresql</code>. The <code class="literal">resource-root path</code> attribute should specify the JAR filename of the driver. The rest are just the normal dependencies that any JDBC driver JAR would have.
			</p></section><section class="section" id="declare_and_load_jdbc_driver"><div class="titlepage"><div><div><h2 class="title">6.3. Declare and Load JDBC Driver</h2></div></div></div><p>
				The next thing you have to do is declare your newly packaged JDBC driver into your deployment profile so that it loads and becomes available when the server boots up. Where you perform this action depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>. If you’re deploying in standard mode, edit <span class="emphasis"><em>…​/standalone/configuration/standalone.xml</em></span>. If you’re deploying in standard clustering mode, edit <span class="emphasis"><em>…​/standalone/configuration/standalone-ha.xml</em></span>. If you’re deploying in domain mode, edit <span class="emphasis"><em>…​/domain/configuration/domain.xml</em></span>. In domain mode, you’ll need to make sure you edit the profile you are using: either <code class="literal">auth-server-standalone</code> or <code class="literal">auth-server-clustered</code>
			</p><p>
				Within the profile, search for the <code class="literal">drivers</code> XML block within the <code class="literal">datasources</code> subsystem. You should see a pre-defined driver declared for the H2 JDBC driver. This is where you’ll declare the JDBC driver for your external database.
			</p><div class="formalpara"><p class="title"><strong>JDBC Drivers</strong></p><p>
					
<pre class="programlisting language-xml">  &lt;subsystem xmlns="urn:jboss:domain:datasources:5.0"&gt;
     &lt;datasources&gt;
       ...
       &lt;drivers&gt;
          &lt;driver name="h2" module="com.h2database.h2"&gt;
              &lt;xa-datasource-class&gt;org.h2.jdbcx.JdbcDataSource&lt;/xa-datasource-class&gt;
          &lt;/driver&gt;
       &lt;/drivers&gt;
     &lt;/datasources&gt;
  &lt;/subsystem&gt;</pre>
				</p></div><p>
				Within the <code class="literal">drivers</code> XML block you’ll need to declare an additional JDBC driver. It needs to have a <code class="literal">name</code> which you can choose to be anything you want. You specify the <code class="literal">module</code> attribute which points to the <code class="literal">module</code> package you created earlier for the driver JAR. Finally you have to specify the driver’s Java class. Here’s an example of installing PostgreSQL driver that lives in the module example defined earlier in this chapter.
			</p><div class="formalpara"><p class="title"><strong>Declare Your JDBC Drivers</strong></p><p>
					
<pre class="programlisting language-xml">  &lt;subsystem xmlns="urn:jboss:domain:datasources:5.0"&gt;
     &lt;datasources&gt;
       ...
       &lt;drivers&gt;
          &lt;driver name="postgresql" module="org.postgresql"&gt;
              &lt;xa-datasource-class&gt;org.postgresql.xa.PGXADataSource&lt;/xa-datasource-class&gt;
          &lt;/driver&gt;
          &lt;driver name="h2" module="com.h2database.h2"&gt;
              &lt;xa-datasource-class&gt;org.h2.jdbcx.JdbcDataSource&lt;/xa-datasource-class&gt;
          &lt;/driver&gt;
       &lt;/drivers&gt;
     &lt;/datasources&gt;
  &lt;/subsystem&gt;</pre>
				</p></div></section><section class="section" id="modify_the_red_hat_single_sign_on_datasource"><div class="titlepage"><div><div><h2 class="title">6.4. Modify the Red Hat Single Sign-On Datasource</h2></div></div></div><p>
				After declaring your JDBC driver, you have to modify the existing datasource configuration that Red Hat Single Sign-On uses to connect it to your new external database. You’ll do this within the same configuration file and XML block that you registered your JDBC driver in. Here’s an example that sets up the connection to your new database:
			</p><div class="formalpara"><p class="title"><strong>Declare Your JDBC Drivers</strong></p><p>
					
<pre class="programlisting language-xml">  &lt;subsystem xmlns="urn:jboss:domain:datasources:5.0"&gt;
     &lt;datasources&gt;
       ...
       &lt;datasource jndi-name="java:jboss/datasources/KeycloakDS" pool-name="KeycloakDS" enabled="true" use-java-context="true"&gt;
           &lt;connection-url&gt;jdbc:postgresql://localhost/keycloak&lt;/connection-url&gt;
           &lt;driver&gt;postgresql&lt;/driver&gt;
           &lt;pool&gt;
               &lt;max-pool-size&gt;20&lt;/max-pool-size&gt;
           &lt;/pool&gt;
           &lt;security&gt;
               &lt;user-name&gt;William&lt;/user-name&gt;
               &lt;password&gt;password&lt;/password&gt;
           &lt;/security&gt;
       &lt;/datasource&gt;
        ...
     &lt;/datasources&gt;
  &lt;/subsystem&gt;</pre>
				</p></div><p>
				Search for the <code class="literal">datasource</code> definition for <code class="literal">KeycloakDS</code>. You’ll first need to modify the <code class="literal">connection-url</code>. The documentation for your vendor’s JDBC implementation should specify the format for this connection URL value.
			</p><p>
				Next define the <code class="literal">driver</code> you will use. This is the logical name of the JDBC driver you declared in the previous section of this chapter.
			</p><p>
				It is expensive to open a new connection to a database every time you want to perform a transaction. To compensate, the datasource implementation maintains a pool of open connections. The <code class="literal">max-pool-size</code> specifies the maximum number of connections it will pool. You may want to change the value of this depending on the load of your system.
			</p><p>
				Finally, with PostgreSQL at least, you need to define the database username and password that is needed to connect to the database. You may be worried that this is in clear text in the example. There are methods to obfuscate this, but this is beyond the scope of this guide.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					For more information about datasource features, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#datasource_management">the datasource configuration chapter</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
				</p></div></div></section><section class="section" id="database_configuration"><div class="titlepage"><div><div><h2 class="title">6.5. Database Configuration</h2></div></div></div><p>
				The configuration for this component is found in the <code class="literal">standalone.xml</code>, <code class="literal">standalone-ha.xml</code>, or <code class="literal">domain.xml</code> file in your distribution. The location of this file depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>.
			</p><div class="formalpara"><p class="title"><strong>Database Config</strong></p><p>
					
<pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:keycloak-server:1.1"&gt;
    ...
    &lt;spi name="connectionsJpa"&gt;
     &lt;provider name="default" enabled="true"&gt;
         &lt;properties&gt;
             &lt;property name="dataSource" value="java:jboss/datasources/KeycloakDS"/&gt;
             &lt;property name="initializeEmpty" value="false"/&gt;
             &lt;property name="migrationStrategy" value="manual"/&gt;
             &lt;property name="migrationExport" value="${jboss.home.dir}/keycloak-database-update.sql"/&gt;
         &lt;/properties&gt;
     &lt;/provider&gt;
    &lt;/spi&gt;
    ...
&lt;/subsystem&gt;</pre>
				</p></div><p>
				Possible configuration options are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">dataSource</span></dt><dd>
							JNDI name of the dataSource
						</dd><dt><span class="term">jta</span></dt><dd>
							boolean property to specify if datasource is JTA capable
						</dd><dt><span class="term">driverDialect</span></dt><dd>
							Value of database dialect. In most cases you don’t need to specify this property as dialect will be autodetected by Hibernate.
						</dd><dt><span class="term">initializeEmpty</span></dt><dd>
							Initialize database if empty. If set to false the database has to be manually initialized. If you want to manually initialize the database set migrationStrategy to <code class="literal">manual</code> which will create a file with SQL commands to initialize the database. Defaults to true.
						</dd><dt><span class="term">migrationStrategy</span></dt><dd>
							Strategy to use to migrate database. Valid values are <code class="literal">update</code>, <code class="literal">manual</code> and <code class="literal">validate</code>. Update will automatically migrate the database schema. Manual will export the required changes to a file with SQL commands that you can manually execute on the database. Validate will simply check if the database is up-to-date.
						</dd><dt><span class="term">migrationExport</span></dt><dd>
							Path for where to write manual database initialization/migration file.
						</dd><dt><span class="term">showSql</span></dt><dd>
							Specify whether Hibernate should show all SQL commands in the console (false by default). This is very verbose!
						</dd><dt><span class="term">formatSql</span></dt><dd>
							Specify whether Hibernate should format SQL commands (true by default)
						</dd><dt><span class="term">globalStatsInterval</span></dt><dd>
							Will log global statistics from Hibernate about executed DB queries and other things. Statistics are always reported to server log at specified interval (in seconds) and are cleared after each report.
						</dd><dt><span class="term">schema</span></dt><dd>
							Specify the database schema to use
						</dd></dl></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					These configuration switches and more are described in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/development_guide/#java_persistence_api"><span class="emphasis"><em>JBoss EAP Development Guide</em></span></a>.
				</p></div></div></section><section class="section" id="unicode_considerations_for_databases"><div class="titlepage"><div><div><h2 class="title">6.6. Unicode Considerations for Databases</h2></div></div></div><p>
				Database schema in Red Hat Single Sign-On only accounts for Unicode strings in the following special fields:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Realms: display name, HTML display name
					</li><li class="listitem">
						Federation Providers: display name
					</li><li class="listitem">
						Users: username, given name, last name, attribute names and values
					</li><li class="listitem">
						Groups: name, attribute names and values
					</li><li class="listitem">
						Roles: name
					</li><li class="listitem">
						Descriptions of objects
					</li></ul></div><p>
				Otherwise, characters are limited to those contained in database encoding which is often 8-bit. However, for some database systems, it is possible to enable UTF-8 encoding of Unicode characters and use full Unicode character set in all text fields. Often, this is counterbalanced by shorter maximum length of the strings than in case of 8-bit encodings.
			</p><p>
				Some of the databases require special settings to database and/or JDBC driver to be able to handle Unicode characters. Please find the settings for your database below. Note that if a database is listed here, it can still work properly provided it handles UTF-8 encoding properly both on the level of database and JDBC driver.
			</p><p>
				Technically, the key criterion for Unicode support for all fields is whether the database allows setting of Unicode character set for <code class="literal">VARCHAR</code> and <code class="literal">CHAR</code> fields. If yes, there is a high chance that Unicode will be plausible, usually at the expense of field length. If it only supports Unicode in <code class="literal">NVARCHAR</code> and <code class="literal">NCHAR</code> fields, Unicode support for all text fields is unlikely as Keycloak schema uses <code class="literal">VARCHAR</code> and <code class="literal">CHAR</code> fields extensively.
			</p><section class="section" id="oracle_database"><div class="titlepage"><div><div><h3 class="title">6.6.1. Oracle Database</h3></div></div></div><p>
					Unicode characters are properly handled provided the database was created with Unicode support in <code class="literal">VARCHAR</code> and <code class="literal">CHAR</code> fields (e.g. by using <code class="literal">AL32UTF8</code> character set as the database character set). No special settings is needed for JDBC driver.
				</p><p>
					If the database character set is not Unicode, then to use Unicode characters in the special fields, the JDBC driver needs to be configured with the connection property <code class="literal">oracle.jdbc.defaultNChar</code> set to <code class="literal">true</code>. It might be wise, though not strictly necessary, to also set the <code class="literal">oracle.jdbc.convertNcharLiterals</code> connection property to <code class="literal">true</code>. These properties can be set either as system properties or as connection properties. Please note that setting <code class="literal">oracle.jdbc.defaultNChar</code> may have negative impact on performance. For details, please refer to Oracle JDBC driver configuration documentation.
				</p></section><section class="section" id="microsoft_sql_server_database"><div class="titlepage"><div><div><h3 class="title">6.6.2. Microsoft SQL Server Database</h3></div></div></div><p>
					Unicode characters are properly handled only for the special fields. No special settings of JDBC driver or database is necessary.
				</p></section><section class="section" id="mysql_database"><div class="titlepage"><div><div><h3 class="title">6.6.3. MySQL Database</h3></div></div></div><p>
					Unicode characters are properly handled provided the database was created with Unicode support in <code class="literal">VARCHAR</code> and <code class="literal">CHAR</code> fields in the <code class="literal">CREATE DATABASE</code> command (e.g. by using <code class="literal">utf8</code> character set as the default database character set in MySQL 5.5. Please note that <code class="literal">utf8mb4</code> character set does not work due to different storage requirements to <code class="literal">utf8</code> character set <a href="#ftn.idm140154417423296" class="footnote"><sup class="footnote" id="idm140154417423296">[1]</sup></a>). Note that in this case, length restriction to non-special fields does not apply because columns are created to accommodate given amount of characters, not bytes. If the database default character set does not allow storing Unicode, only the special fields allow storing Unicode values.
				</p><p>
					At the side of JDBC driver settings, it is necessary to add a connection property <code class="literal">characterEncoding=UTF-8</code> to the JDBC connection settings.
				</p></section><section class="section" id="postgresql_database"><div class="titlepage"><div><div><h3 class="title">6.6.4. PostgreSQL Database</h3></div></div></div><p>
					Unicode is supported when the database character set is <code class="literal">UTF8</code>. In that case, Unicode characters can be used in any field, there is no reduction of field length for non-special fields. No special settings of JDBC driver is necessary.
				</p></section><div class="footnotes"><br/><hr width="100" align="left"/><div id="ftn.idm140154417423296" class="footnote"><div class="para"><a href="#idm140154417423296" class="simpara"><sup class="simpara">[1] </sup></a>
						Tracked as <a class="link" href="https://issues.jboss.org/browse/KEYCLOAK-3873">https://issues.jboss.org/browse/KEYCLOAK-3873</a>
					</div></div></div></section></section><section class="chapter" id="network"><div class="titlepage"><div><div><h1 class="title">Chapter 7. Network Setup</h1></div></div></div><p>
			Red Hat Single Sign-On can run out of the box with some networking limitations. For one, all network endpoints bind to <code class="literal">localhost</code> so the auth server is really only usable on one local machine. For HTTP based connections, it does not use default ports like 80 and 443. HTTPS/SSL is not configured out of the box and without it, Red Hat Single Sign-On has many security vulnerabilities. Finally, Red Hat Single Sign-On may often need to make secure SSL and HTTPS connections to external servers and thus need a trust store set up so that endpoints can be validated correctly. This chapter discusses all of these things.
		</p><section class="section" id="bind-address"><div class="titlepage"><div><div><h2 class="title">7.1. Bind Addresses</h2></div></div></div><p>
				By default Red Hat Single Sign-On binds to the localhost loopback address <code class="literal">127.0.0.1</code>. That’s not a very useful default if you want the authentication server available on your network. Generally, what we recommend is that you deploy a reverse proxy or load balancer on a public network and route traffic to individual Red Hat Single Sign-On server instances on a private network. In either case though, you still need to set up your network interfaces to bind to something other than <code class="literal">localhost</code>.
			</p><p>
				Setting the bind address is quite easy and can be done on the command line with either the <span class="emphasis"><em>standalone.sh</em></span> or <span class="emphasis"><em>domain.sh</em></span> boot scripts discussed in the <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">Choosing an Operating Mode</a> chapter.
			</p><pre class="screen">$ standalone.sh -b 192.168.0.5</pre><p>
				The <code class="literal">-b</code> switch sets the IP bind address for any public interfaces.
			</p><p>
				Alternatively, if you don’t want to set the bind address at the command line, you can edit the profile configuration of your deployment. Open up the profile configuration file (<span class="emphasis"><em>standalone.xml</em></span> or <span class="emphasis"><em>domain.xml</em></span> depending on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>) and look for the <code class="literal">interfaces</code> XML block.
			</p><pre class="programlisting language-xml">    &lt;interfaces&gt;
        &lt;interface name="management"&gt;
            &lt;inet-address value="${jboss.bind.address.management:127.0.0.1}"/&gt;
        &lt;/interface&gt;
        &lt;interface name="public"&gt;
            &lt;inet-address value="${jboss.bind.address:127.0.0.1}"/&gt;
        &lt;/interface&gt;
    &lt;/interfaces&gt;</pre><p>
				The <code class="literal">public</code> interface corresponds to subsystems creating sockets that are available publicly. An example of one of these subsystems is the web layer which serves up the authentication endpoints of Red Hat Single Sign-On. The <code class="literal">management</code> interface corresponds to sockets opened up by the management layer of the JBoss EAP. Specifically the sockets which allow you to use the <code class="literal">jboss-cli.sh</code> command line interface and the JBoss EAP web console.
			</p><p>
				In looking at the <code class="literal">public</code> interface you see that it has a special string <code class="literal">${jboss.bind.address:127.0.0.1}</code>. This string denotes a value <code class="literal">127.0.0.1</code> that can be overridden on the command line by setting a Java system property, i.e.:
			</p><pre class="screen">$ domain.sh -Djboss.bind.address=192.168.0.5</pre><p>
				The <code class="literal">-b</code> is just a shorthand notation for this command. So, you can either change the bind address value directly in the profile config, or change it on the command line when you boot up.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					There are many more options available when setting up <code class="literal">interface</code> definitions. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#network_and_port_configuration">the network interface</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
				</p></div></div></section><section class="section" id="ports"><div class="titlepage"><div><div><h2 class="title">7.2. Socket Port Bindings</h2></div></div></div><p>
				The ports opened for each socket have a pre-defined default that can be overridden at the command line or within configuration. To illustrate this configuration, let’s pretend you are running in <a class="link" href="#standalone-mode" title="3.1. Standalone Mode">standalone mode</a> and open up the <span class="emphasis"><em>…​/standalone/configuration/standalone.xml</em></span>. Search for <code class="literal">socket-binding-group</code>.
			</p><pre class="programlisting language-xml">    &lt;socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}"&gt;
        &lt;socket-binding name="management-http" interface="management" port="${jboss.management.http.port:9990}"/&gt;
        &lt;socket-binding name="management-https" interface="management" port="${jboss.management.https.port:9993}"/&gt;
        &lt;socket-binding name="ajp" port="${jboss.ajp.port:8009}"/&gt;
        &lt;socket-binding name="http" port="${jboss.http.port:8080}"/&gt;
        &lt;socket-binding name="https" port="${jboss.https.port:8443}"/&gt;
        &lt;socket-binding name="txn-recovery-environment" port="4712"/&gt;
        &lt;socket-binding name="txn-status-manager" port="4713"/&gt;
        &lt;outbound-socket-binding name="mail-smtp"&gt;
            &lt;remote-destination host="localhost" port="25"/&gt;
        &lt;/outbound-socket-binding&gt;
    &lt;/socket-binding-group&gt;</pre><p>
				<code class="literal">socket-bindings</code> define socket connections that will be opened by the server. These bindings specify the <code class="literal">interface</code> (bind address) they use as well as what port number they will open. The ones you will be most interested in are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">http</span></dt><dd>
							Defines the port used for Red Hat Single Sign-On HTTP connections
						</dd><dt><span class="term">https</span></dt><dd>
							Defines the port used for Red Hat Single Sign-On HTTPS connections
						</dd><dt><span class="term">ajp</span></dt><dd>
							This socket binding defines the port used for the AJP protocol. This protocol is used by Apache HTTPD server in conjunction <code class="literal">mod-cluster</code> when you are using Apache HTTPD as a load balancer.
						</dd><dt><span class="term">management-http</span></dt><dd>
							Defines the HTTP connection used by JBoss EAP CLI and web console.
						</dd></dl></div><p>
				When running in <a class="link" href="#domain-mode" title="3.3. Domain Clustered Mode">domain mode</a> setting the socket configurations is a bit trickier as the example <span class="emphasis"><em>domain.xml</em></span> file has multiple <code class="literal">socket-binding-groups</code> defined. If you scroll down to the <code class="literal">server-group</code> definitions you can see what <code class="literal">socket-binding-group</code> is used for each <code class="literal">server-group</code>.
			</p><div class="formalpara"><p class="title"><strong>domain socket bindings</strong></p><p>
					
<pre class="programlisting language-xml">    &lt;server-groups&gt;
        &lt;server-group name="load-balancer-group" profile="load-balancer"&gt;
            ...
            &lt;socket-binding-group ref="load-balancer-sockets"/&gt;
        &lt;/server-group&gt;
        &lt;server-group name="auth-server-group" profile="auth-server-clustered"&gt;
            ...
            &lt;socket-binding-group ref="ha-sockets"/&gt;
        &lt;/server-group&gt;
    &lt;/server-groups&gt;</pre>
				</p></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					There are many more options available when setting up <code class="literal">socket-binding-group</code> definitions. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#network_and_port_configuration">the socket binding group</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
				</p></div></div></section><section class="section" id="setting_up_https_ssl"><div class="titlepage"><div><div><h2 class="title">7.3. Setting up HTTPS/SSL</h2></div></div></div><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
					Red Hat Single Sign-On is not set up by default to handle SSL/HTTPS. It is highly recommended that you either enable SSL on the Red Hat Single Sign-On server itself or on a reverse proxy in front of the Red Hat Single Sign-On server.
				</p></div></div><p>
				This default behavior is defined by the SSL/HTTPS mode of each Red Hat Single Sign-On realm. This is discussed in more detail in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_administration_guide/">Server Administration Guide</a>, but let’s give some context and a brief overview of these modes.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">external requests</span></dt><dd>
							Red Hat Single Sign-On can run out of the box without SSL so long as you stick to private IP addresses like <code class="literal">localhost</code>, <code class="literal">127.0.0.1</code>, <code class="literal">10.0.x.x</code>, <code class="literal">192.168.x.x</code>, and <code class="literal">172.16.x.x</code>. If you don’t have SSL/HTTPS configured on the server or you try to access Red Hat Single Sign-On over HTTP from a non-private IP adress you will get an error.
						</dd><dt><span class="term">none</span></dt><dd>
							Red Hat Single Sign-On does not require SSL. This should really only be used in development when you are playing around with things.
						</dd><dt><span class="term">all requests</span></dt><dd>
							Red Hat Single Sign-On requires SSL for all IP addresses.
						</dd></dl></div><p>
				The SSL mode for each realm can be configured in the Red Hat Single Sign-On admin console.
			</p><section class="section" id="enabling_ssl_https_for_the_red_hat_single_sign_on_server"><div class="titlepage"><div><div><h3 class="title">7.3.1. Enabling SSL/HTTPS for the Red Hat Single Sign-On Server</h3></div></div></div><p>
					If you are not using a reverse proxy or load balancer to handle HTTPS traffic for you, you’ll need to enable HTTPS for the Red Hat Single Sign-On server. This involves
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Obtaining or generating a keystore that contains the private key and certificate for SSL/HTTP traffic
						</li><li class="listitem">
							Configuring the Red Hat Single Sign-On server to use this keypair and certificate.
						</li></ol></div><section class="section" id="creating_the_certificate_and_java_keystore"><div class="titlepage"><div><div><h4 class="title">7.3.1.1. Creating the Certificate and Java Keystore</h4></div></div></div><p>
						In order to allow HTTPS connections, you need to obtain a self signed or third-party signed certificate and import it into a Java keystore before you can enable HTTPS in the web container you are deploying the Red Hat Single Sign-On Server to.
					</p><section class="section" id="self_signed_certificate"><div class="titlepage"><div><div><h5 class="title">7.3.1.1.1. Self Signed Certificate</h5></div></div></div><p>
							In development, you will probably not have a third party signed certificate available to test a Red Hat Single Sign-On deployment so you’ll need to generate a self-signed one using the <code class="literal">keytool</code> utility that comes with the Java JDK.
						</p><pre class="screen">$ keytool -genkey -alias localhost -keyalg RSA -keystore keycloak.jks -validity 10950
    Enter keystore password: secret
    Re-enter new password: secret
    What is your first and last name?
    [Unknown]:  localhost
    What is the name of your organizational unit?
    [Unknown]:  Keycloak
    What is the name of your organization?
    [Unknown]:  Red Hat
    What is the name of your City or Locality?
    [Unknown]:  Westford
    What is the name of your State or Province?
    [Unknown]:  MA
    What is the two-letter country code for this unit?
    [Unknown]:  US
    Is CN=localhost, OU=Keycloak, O=Test, L=Westford, ST=MA, C=US correct?
    [no]:  yes</pre><p>
							You should answer <code class="literal">What is your first and last name ?</code> question with the DNS name of the machine you’re installing the server on. For testing purposes, <code class="literal">localhost</code> should be used. After executing this command, the <code class="literal">keycloak.jks</code> file will be generated in the same directory as you executed the <code class="literal">keytool</code> command in.
						</p><p>
							If you want a third-party signed certificate, but don’t have one, you can obtain one for free at <a class="link" href="http://www.cacert.org">cacert.org</a>. You’ll have to do a little set up first before doing this though.
						</p><p>
							The first thing to do is generate a Certificate Request:
						</p><pre class="screen">$ keytool -certreq -alias yourdomain -keystore keycloak.jks &gt; keycloak.careq</pre><p>
							Where <code class="literal">yourdomain</code> is a DNS name for which this certificate is generated for. Keytool generates the request:
						</p><pre class="screen">-----BEGIN NEW CERTIFICATE REQUEST-----
MIIC2jCCAcICAQAwZTELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAk1BMREwDwYDVQQHEwhXZXN0Zm9y
ZDEQMA4GA1UEChMHUmVkIEhhdDEQMA4GA1UECxMHUmVkIEhhdDESMBAGA1UEAxMJbG9jYWxob3N0
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAr7kck2TaavlEOGbcpi9c0rncY4HhdzmY
Ax2nZfq1eZEaIPqI5aTxwQZzzLDK9qbeAd8Ji79HzSqnRDxNYaZu7mAYhFKHgixsolE3o5Yfzbw1
29RvyeUVe+WZxv5oo9wolVVpdSINIMEL2LaFhtX/c1dqiqYVpfnvFshZQaIg2nL8juzZcBjj4as
H98gIS7khql/dkZKsw9NLvyxgJvp7PaXurX29fNf3ihG+oFrL22oFyV54BWWxXCKU/GPn61EGZGw
Ft2qSIGLdctpMD1aJR2bcnlhEjZKDksjQZoQ5YMXaAGkcYkG6QkgrocDE2YXDbi7GIdf9MegVJ35
2DQMpwIDAQABoDAwLgYJKoZIhvcNAQkOMSEwHzAdBgNVHQ4EFgQUQwlZJBA+fjiDdiVzaO9vrE/i
n2swDQYJKoZIhvcNAQELBQADggEBAC5FRvMkhal3q86tHPBYWBuTtmcSjs4qUm6V6f63frhveWHf
PzRrI1xH272XUIeBk0gtzWo0nNZnf0mMCtUBbHhhDcG82xolikfqibZijoQZCiGiedVjHJFtniDQ
9bMDUOXEMQ7gHZg5q6mJfNG9MbMpQaUVEEFvfGEQQxbiFK7hRWU8S23/d80e8nExgQxdJWJ6vd0X
MzzFK6j4Dj55bJVuM7GFmfdNC52pNOD5vYe47Aqh8oajHX9XTycVtPXl45rrWAH33ftbrS8SrZ2S
vqIFQeuLL3BaHwpl3t7j2lMWcK1p80laAxEASib/fAwrRHpLHBXRcq6uALUOZl4Alt8=
-----END NEW CERTIFICATE REQUEST-----</pre><p>
							Send this ca request to your CA. The CA will issue you a signed certificate and send it to you. Before you import your new cert, you must obtain and import the root certificate of the CA. You can download the cert from CA (ie.: root.crt) and import as follows:
						</p><pre class="screen">$ keytool -import -keystore keycloak.jks -file root.crt -alias root</pre><p>
							Last step is to import your new CA generated certificate to your keystore:
						</p><pre class="screen">$ keytool -import -alias yourdomain -keystore keycloak.jks -file your-certificate.cer</pre></section></section><section class="section" id="configure_red_hat_single_sign_on_to_use_the_keystore"><div class="titlepage"><div><div><h4 class="title">7.3.1.2. Configure Red Hat Single Sign-On to Use the Keystore</h4></div></div></div><p>
						Now that you have a Java keystore with the appropriate certificates, you need to configure your Red Hat Single Sign-On installation to use it. First, you must edit the <span class="emphasis"><em>standalone.xml</em></span>, <span class="emphasis"><em>standalone-ha.xml</em></span>, or <span class="emphasis"><em>host.xml</em></span> file to use the keystore and enable HTTPS. You may then either move the keystore file to the <span class="emphasis"><em>configuration/</em></span> directory of your deployment or the file in a location you choose and provide an absolute path to it. If you are using absolute paths, remove the optional <code class="literal">relative-to</code> parameter from your configuration (See <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>).
					</p><p>
						Add the new <code class="literal">security-realm</code> element using the CLI:
					</p><pre class="screen">$ /core-service=management/security-realm=UndertowRealm:add()

$ /core-service=management/security-realm=UndertowRealm/server-identity=ssl:add(keystore-path=keycloak.jks, keystore-relative-to=jboss.server.config.dir, keystore-password=secret)</pre><p>
						If using domain mode, the commands should be executed in every host using the <code class="literal">/host=&lt;host_name&gt;/</code> prefix (in order to create the <code class="literal">security-realm</code> in all of them), like this, which you would repeat for each host:
					</p><pre class="screen">$ /host=&lt;host_name&gt;/core-service=management/security-realm=UndertowRealm/server-identity=ssl:add(keystore-path=keycloak.jks, keystore-relative-to=jboss.server.config.dir, keystore-password=secret)</pre><p>
						In the standalone or host configuration file, the <code class="literal">security-realms</code> element should look like this:
					</p><pre class="programlisting language-xml">&lt;security-realm name="UndertowRealm"&gt;
    &lt;server-identities&gt;
        &lt;ssl&gt;
            &lt;keystore path="keycloak.jks" relative-to="jboss.server.config.dir" keystore-password="secret" /&gt;
        &lt;/ssl&gt;
    &lt;/server-identities&gt;
&lt;/security-realm&gt;</pre><p>
						Next, in the standalone or each domain configuration file, search for any instances of <code class="literal">security-realm</code>. Modify the <code class="literal">https-listener</code> to use the created realm:
					</p><pre class="screen">$ /subsystem=undertow/server=default-server/https-listener=https:write-attribute(name=security-realm, value=UndertowRealm)</pre><p>
						If using domain mode, prefix the command with the profile that is being used with: <code class="literal">/profile=&lt;profile_name&gt;/</code>.
					</p><p>
						The resulting element, <code class="literal">server name="default-server"</code>, which is a child element of <code class="literal">subsystem xmlns="urn:jboss:domain:undertow:9.0"</code>, should contain the following stanza:
					</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:undertow:9.0"&gt;
   &lt;buffer-cache name="default"/&gt;
   &lt;server name="default-server"&gt;
      &lt;https-listener name="https" socket-binding="https" security-realm="UndertowRealm"/&gt;
   ...
&lt;/subsystem&gt;</pre></section></section></section><section class="section" id="outgoing_http_requests"><div class="titlepage"><div><div><h2 class="title">7.4. Outgoing HTTP Requests</h2></div></div></div><p>
				The Red Hat Single Sign-On server often needs to make non-browser HTTP requests to the applications and services it secures. The auth server manages these outgoing connections by maintaining an HTTP client connection pool. There are some things you’ll need to configure in <code class="literal">standalone.xml</code>, <code class="literal">standalone-ha.xml</code>, or <code class="literal">domain.xml</code>. The location of this file depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>.
			</p><div class="formalpara"><p class="title"><strong>HTTP client Config example</strong></p><p>
					
<pre class="programlisting language-xml">&lt;spi name="connectionsHttpClient"&gt;
    &lt;provider name="default" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property name="connection-pool-size" value="256"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
&lt;/spi&gt;</pre>
				</p></div><p>
				Possible configuration options are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">establish-connection-timeout-millis</span></dt><dd>
							Timeout for establishing a socket connection.
						</dd><dt><span class="term">socket-timeout-millis</span></dt><dd>
							If an outgoing request does not receive data for this amount of time, timeout the connection.
						</dd><dt><span class="term">connection-pool-size</span></dt><dd>
							How many connections can be in the pool (128 by default).
						</dd><dt><span class="term">max-pooled-per-route</span></dt><dd>
							How many connections can be pooled per host (64 by default).
						</dd><dt><span class="term">connection-ttl-millis</span></dt><dd>
							Maximum connection time to live in milliseconds. Not set by default.
						</dd><dt><span class="term">max-connection-idle-time-millis</span></dt><dd>
							Maximum time the connection might stay idle in the connection pool (900 seconds by default). Will start background cleaner thread of Apache HTTP client. Set to <code class="literal">-1</code> to disable this checking and the background thread.
						</dd><dt><span class="term">disable-cookies</span></dt><dd>
							<code class="literal">true</code> by default. When set to true, this will disable any cookie caching.
						</dd><dt><span class="term">client-keystore</span></dt><dd>
							This is the file path to a Java keystore file. This keystore contains client certificate for two-way SSL.
						</dd><dt><span class="term">client-keystore-password</span></dt><dd>
							Password for the client keystore. This is <span class="emphasis"><em>REQUIRED</em></span> if <code class="literal">client-keystore</code> is set.
						</dd><dt><span class="term">client-key-password</span></dt><dd>
							Password for the client’s key. This is <span class="emphasis"><em>REQUIRED</em></span> if <code class="literal">client-keystore</code> is set.
						</dd><dt><span class="term">proxy-mappings</span></dt><dd>
							Denotes proxy configurations for outgoing HTTP requests. See the section on <a class="link" href="#proxymappings" title="7.4.1. Proxy Mappings for Outgoing HTTP Requests">Proxy Mappings for Outgoing HTTP Requests</a> for more details.
						</dd></dl></div><section class="section" id="proxymappings"><div class="titlepage"><div><div><h3 class="title">7.4.1. Proxy Mappings for Outgoing HTTP Requests</h3></div></div></div><p>
					Outgoing HTTP requests sent by Red Hat Single Sign-On can optionally use a proxy server based on a comma delimited list of proxy-mappings. A proxy-mapping denotes the combination of a regex based hostname pattern and a proxy-uri in the form of <code class="literal">hostnamePattern;proxyUri</code>, e.g.:
				</p><pre class="screen">.*\.(google|googleapis)\.com;http://www-proxy.acme.com:8080</pre><p>
					To determine the proxy for an outgoing HTTP request the target hostname is matched against the configured hostname patterns. The first matching pattern determines the proxy-uri to use. If none of the configured patterns match for the given hostname then no proxy is used.
				</p><p>
					The special value <code class="literal">NO_PROXY</code> for the proxy-uri can be used to indicate that no proxy should be used for hosts matching the associated hostname pattern. It is possible to specify a catch-all pattern at the end of the proxy-mappings to define a default proxy for all outgoing requests.
				</p><p>
					The following example demonstrates the proxy-mapping configuration.
				</p><pre class="screen"># All requests to Google APIs should use http://www-proxy.acme.com:8080 as proxy
.*\.(google|googleapis)\.com;http://www-proxy.acme.com:8080

# All requests to internal systems should use no proxy
.*\.acme\.com;NO_PROXY

# All other requests should use http://fallback:8080 as proxy
.*;http://fallback:8080</pre><p>
					This can be configured via the following <code class="literal">jboss-cli</code> command. Note that you need to properly escape the regex-pattern as shown below.
				</p><pre class="screen">echo SETUP: Configure proxy routes for HttpClient SPI

# In case there is no connectionsHttpClient definition yet
/subsystem=keycloak-server/spi=connectionsHttpClient/provider=default:add(enabled=true)

# Configure the proxy-mappings
/subsystem=keycloak-server/spi=connectionsHttpClient/provider=default:write-attribute(name=properties.proxy-mappings,value=[".*\\.(google|googleapis)\\.com;http://www-proxy.acme.com:8080",".*\\.acme\\.com;NO_PROXY",".*;http://fallback:8080"])</pre><p>
					The <code class="literal">jboss-cli</code> command results in the following subsystem configuration. Note that one needs to encode <code class="literal">"</code> characters with <code class="literal">&amp;quot;</code>.
				</p><pre class="programlisting language-xml">&lt;spi name="connectionsHttpClient"&gt;
    &lt;provider name="default" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property
            name="proxy-mappings"
            value="[&amp;quot;.*\\.(google|googleapis)\\.com;http://www-proxy.acme.com:8080&amp;quot;,&amp;quot;.*\\.acme\\.com;NO_PROXY&amp;quot;,&amp;quot;.*;http://fallback:8080&amp;quot;]"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
&lt;/spi&gt;</pre></section><section class="section" id="truststore"><div class="titlepage"><div><div><h3 class="title">7.4.2. Outgoing HTTPS Request Truststore</h3></div></div></div><p>
					When Red Hat Single Sign-On invokes on remote HTTPS endpoints, it has to validate the remote server’s certificate in order to ensure it is connecting to a trusted server. This is necessary in order to prevent man-in-the-middle attacks. The certificates of these remote server’s or the CA that signed these certificates must be put in a truststore. This truststore is managed by the Red Hat Single Sign-On server.
				</p><p>
					The truststore is used when connecting securely to identity brokers, LDAP identity providers, when sending emails, and for backchannel communication with client applications.
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						By default, a truststore provider is not configured, and any https connections fall back to standard java truststore configuration as described in <a class="link" href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/jsse/JSSERefGuide.html">Java’s JSSE Reference Guide</a>. If there is no trust established, then these outgoing HTTPS requests will fail.
					</p></div></div><p>
					You can use <span class="emphasis"><em>keytool</em></span> to create a new truststore file or add trusted host certificates to an existing one:
				</p><pre class="screen">$ keytool -import -alias HOSTDOMAIN -keystore truststore.jks -file host-certificate.cer</pre><p>
					The truststore is configured within the <code class="literal">standalone.xml</code>, <code class="literal">standalone-ha.xml</code>, or <code class="literal">domain.xml</code> file in your distribution. The location of this file depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>. You can add your truststore configuration by using the following template:
				</p><pre class="programlisting language-xml">&lt;spi name="truststore"&gt;
    &lt;provider name="file" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property name="file" value="path to your .jks file containing public certificates"/&gt;
            &lt;property name="password" value="password"/&gt;
            &lt;property name="hostname-verification-policy" value="WILDCARD"/&gt;
            &lt;property name="disabled" value="false"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
&lt;/spi&gt;</pre><p>
					Possible configuration options for this setting are:
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">file</span></dt><dd>
								The path to a Java keystore file. HTTPS requests need a way to verify the host of the server they are talking to. This is what the trustore does. The keystore contains one or more trusted host certificates or certificate authorities. This truststore file should only contain public certificates of your secured hosts. This is <span class="emphasis"><em>REQUIRED</em></span> if <code class="literal">disabled</code> is not true.
							</dd><dt><span class="term">password</span></dt><dd>
								Password for the truststore. This is <span class="emphasis"><em>REQUIRED</em></span> if <code class="literal">disabled</code> is not true.
							</dd><dt><span class="term">hostname-verification-policy</span></dt><dd>
								<code class="literal">WILDCARD</code> by default. For HTTPS requests, this verifies the hostname of the server’s certificate. <code class="literal">ANY</code> means that the hostname is not verified. <code class="literal">WILDCARD</code> Allows wildcards in subdomain names i.e. *.foo.com. <code class="literal">STRICT</code> CN must match hostname exactly.
							</dd><dt><span class="term">disabled</span></dt><dd>
								If true (default value), truststore configuration will be ignored, and certificate checking will fall back to JSSE configuration as described. If set to false, you must configure <code class="literal">file</code>, and <code class="literal">password</code> for the truststore.
							</dd></dl></div></section></section></section><section class="chapter" id="clustering"><div class="titlepage"><div><div><h1 class="title">Chapter 8. Clustering</h1></div></div></div><p>
			This section covers configuring Red Hat Single Sign-On to run in a cluster. There’s a number of things you have to do when setting up a cluster, specifically:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					<a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">Pick an operation mode</a>
				</li><li class="listitem">
					<a class="link" href="#database-1" title="Chapter 6. Relational Database Setup">Configure a shared external database</a>
				</li><li class="listitem">
					Set up a load balancer
				</li><li class="listitem">
					Supplying a private network that supports IP multicast
				</li></ul></div><p>
			Picking an operation mode and configuring a shared database have been discussed earlier in this guide. In this chapter we’ll discuss setting up a load balancer and supplying a private network. We’ll also discuss some issues that you need to be aware of when booting up a host in the cluster.
		</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				It is possible to cluster Red Hat Single Sign-On without IP Multicast, but this topic is beyond the scope of this guide. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#cluster_communication_jgroups">JGroups</a> chapter of the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
			</p></div></div><section class="section" id="recommended_network_architecture"><div class="titlepage"><div><div><h2 class="title">8.1. Recommended Network Architecture</h2></div></div></div><p>
				The recommended network architecture for deploying Red Hat Single Sign-On is to set up an HTTP/HTTPS load balancer on a public IP address that routes requests to Red Hat Single Sign-On servers sitting on a private network. This isolates all clustering connections and provides a nice means of protecting the servers.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					By default, there is nothing to prevent unauthorized nodes from joining the cluster and broadcasting multicast messages. This is why cluster nodes should be in a private network, with a firewall protecting them from outside attacks.
				</p></div></div></section><section class="section" id="clustering_example"><div class="titlepage"><div><div><h2 class="title">8.2. Clustering Example</h2></div></div></div><p>
				Red Hat Single Sign-On does come with an out of the box clustering demo that leverages domain mode. Review the <a class="link" href="#clustered-domain-example" title="3.3.5. Clustered Domain Example">Clustered Domain Example</a> chapter for more details.
			</p></section><section class="section" id="setting-up-a-load-balancer-or-proxy"><div class="titlepage"><div><div><h2 class="title">8.3. Setting Up a Load Balancer or Proxy</h2></div></div></div><p>
				This section discusses a number of things you need to configure before you can put a reverse proxy or load balancer in front of your clustered Red Hat Single Sign-On deployment. It also covers configuring the built in load balancer that was <a class="link" href="#clustered-domain-example" title="3.3.5. Clustered Domain Example">Clustered Domain Example</a>.
			</p><section class="section" id="identifying_client_ip_addresses"><div class="titlepage"><div><div><h3 class="title">8.3.1. Identifying Client IP Addresses</h3></div></div></div><p>
					A few features in Red Hat Single Sign-On rely on the fact that the remote address of the HTTP client connecting to the authentication server is the real IP address of the client machine. Examples include:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Event logs - a failed login attempt would be logged with the wrong source IP address
						</li><li class="listitem">
							SSL required - if the SSL required is set to external (the default) it should require SSL for all external requests
						</li><li class="listitem">
							Authentication flows - a custom authentication flow that uses the IP address to for example show OTP only for external requests
						</li><li class="listitem">
							Dynamic Client Registration
						</li></ul></div><p>
					This can be problematic when you have a reverse proxy or loadbalancer in front of your Red Hat Single Sign-On authentication server. The usual setup is that you have a frontend proxy sitting on a public network that load balances and forwards requests to backend Red Hat Single Sign-On server instances located in a private network. There is some extra configuration you have to do in this scenario so that the actual client IP address is forwarded to and processed by the Red Hat Single Sign-On server instances. Specifically:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Configure your reverse proxy or loadbalancer to properly set <code class="literal">X-Forwarded-For</code> and <code class="literal">X-Forwarded-Proto</code> HTTP headers.
						</li><li class="listitem">
							Configure your reverse proxy or loadbalancer to preserve the original 'Host' HTTP header.
						</li><li class="listitem">
							Configure the authentication server to read the client’s IP address from <code class="literal">X-Forwarded-For</code> header.
						</li></ul></div><p>
					Configuring your proxy to generate the <code class="literal">X-Forwarded-For</code> and <code class="literal">X-Forwarded-Proto</code> HTTP headers and preserving the original <code class="literal">Host</code> HTTP header is beyond the scope of this guide. Take extra precautions to ensure that the <code class="literal">X-Forwarded-For</code> header is set by your proxy. If your proxy isn’t configured correctly, then <span class="emphasis"><em>rogue</em></span> clients can set this header themselves and trick Red Hat Single Sign-On into thinking the client is connecting from a different IP address than it actually is. This becomes really important if you are doing any black or white listing of IP addresses.
				</p><p>
					Beyond the proxy itself, there are a few things you need to configure on the Red Hat Single Sign-On side of things. If your proxy is forwarding requests via the HTTP protocol, then you need to configure Red Hat Single Sign-On to pull the client’s IP address from the <code class="literal">X-Forwarded-For</code> header rather than from the network packet. To do this, open up the profile configuration file (<span class="emphasis"><em>standalone.xml</em></span>, <span class="emphasis"><em>standalone-ha.xml</em></span>, or <span class="emphasis"><em>domain.xml</em></span> depending on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>) and look for the <code class="literal">urn:jboss:domain:undertow:9.0</code> XML block.
				</p><div class="formalpara"><p class="title"><strong><code class="literal">X-Forwarded-For</code> HTTP Config</strong></p><p>
						
<pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:undertow:9.0"&gt;
   &lt;buffer-cache name="default"/&gt;
   &lt;server name="default-server"&gt;
      &lt;ajp-listener name="ajp" socket-binding="ajp"/&gt;
      &lt;http-listener name="default" socket-binding="http" redirect-socket="https"
          proxy-address-forwarding="true"/&gt;
      ...
   &lt;/server&gt;
   ...
&lt;/subsystem&gt;</pre>
					</p></div><p>
					Add the <code class="literal">proxy-address-forwarding</code> attribute to the <code class="literal">http-listener</code> element. Set the value to <code class="literal">true</code>.
				</p><p>
					If your proxy is using the AJP protocol instead of HTTP to forward requests (i.e. Apache HTTPD + mod-cluster), then you have to configure things a little differently. Instead of modifying the <code class="literal">http-listener</code>, you need to add a filter to pull this information from the AJP packets.
				</p><div class="formalpara"><p class="title"><strong><code class="literal">X-Forwarded-For</code> AJP Config</strong></p><p>
						
<pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:undertow:9.0"&gt;
     &lt;buffer-cache name="default"/&gt;
     &lt;server name="default-server"&gt;
         &lt;ajp-listener name="ajp" socket-binding="ajp"/&gt;
         &lt;http-listener name="default" socket-binding="http" redirect-socket="https"/&gt;
         &lt;host name="default-host" alias="localhost"&gt;
             ...
             &lt;filter-ref name="proxy-peer"/&gt;
         &lt;/host&gt;
     &lt;/server&gt;
        ...
     &lt;filters&gt;
         ...
         &lt;filter name="proxy-peer"
                 class-name="io.undertow.server.handlers.ProxyPeerAddressHandler"
                 module="io.undertow.core" /&gt;
     &lt;/filters&gt;
 &lt;/subsystem&gt;</pre>
					</p></div></section><section class="section" id="enable_https_ssl_with_a_reverse_proxy"><div class="titlepage"><div><div><h3 class="title">8.3.2. Enable HTTPS/SSL with a Reverse Proxy</h3></div></div></div><p>
					Assuming that your reverse proxy doesn’t use port 8443 for SSL you also need to configure what port HTTPS traffic is redirected to.
				</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:undertow:9.0"&gt;
    ...
    &lt;http-listener name="default" socket-binding="http"
        proxy-address-forwarding="true" redirect-socket="proxy-https"/&gt;
    ...
&lt;/subsystem&gt;</pre><p>
					Add the <code class="literal">redirect-socket</code> attribute to the <code class="literal">http-listener</code> element. The value should be <code class="literal">proxy-https</code> which points to a socket binding you also need to define.
				</p><p>
					Then add a new <code class="literal">socket-binding</code> element to the <code class="literal">socket-binding-group</code> element:
				</p><pre class="programlisting language-xml">&lt;socket-binding-group name="standard-sockets" default-interface="public"
    port-offset="${jboss.socket.binding.port-offset:0}"&gt;
    ...
    &lt;socket-binding name="proxy-https" port="443"/&gt;
    ...
&lt;/socket-binding-group&gt;</pre></section><section class="section" id="verify_configuration"><div class="titlepage"><div><div><h3 class="title">8.3.3. Verify Configuration</h3></div></div></div><p>
					You can verify the reverse proxy or load balancer configuration by opening the path <code class="literal">/auth/realms/master/.well-known/openid-configuration</code> through the reverse proxy. For example if the reverse proxy address is <code class="literal">https://acme.com/</code> then open the URL <code class="literal">https://acme.com/auth/realms/master/.well-known/openid-configuration</code>. This will show a JSON document listing a number of endpoints for Red Hat Single Sign-On. Make sure the endpoints starts with the address (scheme, domain and port) of your reverse proxy or load balancer. By doing this you make sure that Red Hat Single Sign-On is using the correct endpoint.
				</p><p>
					You should also verify that Red Hat Single Sign-On sees the correct source IP address for requests. Do check this you can try to login to the admin console with an invalid username and/or password. This should show a warning in the server log something like this:
				</p><pre class="screen">08:14:21,287 WARN  XNIO-1 task-45 [org.keycloak.events] type=LOGIN_ERROR, realmId=master, clientId=security-admin-console, userId=8f20d7ba-4974-4811-a695-242c8fbd1bf8, ipAddress=X.X.X.X, error=invalid_user_credentials, auth_method=openid-connect, auth_type=code, redirect_uri=http://localhost:8080/auth/admin/master/console/?redirect_fragment=%2Frealms%2Fmaster%2Fevents-settings, code_id=a3d48b67-a439-4546-b992-e93311d6493e, username=admin</pre><p>
					Check that the value of <code class="literal">ipAddress</code> is the IP address of the machine you tried to login with and not the IP address of the reverse proxy or load balancer.
				</p></section><section class="section" id="using_the_built_in_load_balancer"><div class="titlepage"><div><div><h3 class="title">8.3.4. Using the Built-In Load Balancer</h3></div></div></div><p>
					This section covers configuring the built in load balancer that is discussed in the <a class="link" href="#clustered-domain-example" title="3.3.5. Clustered Domain Example">Clustered Domain Example</a>.
				</p><p>
					The <a class="link" href="#clustered-domain-example" title="3.3.5. Clustered Domain Example">Clustered Domain Example</a> is only designed to run on one machine. To bring up a slave on another host, you’ll need to
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Edit the <span class="emphasis"><em>domain.xml</em></span> file to point to your new host slave
						</li><li class="listitem">
							Copy the server distribution. You don’t need the <span class="emphasis"><em>domain.xml</em></span>, <span class="emphasis"><em>host.xml</em></span>, or <span class="emphasis"><em>host-master.xml</em></span> files. Nor do you need the <span class="emphasis"><em>standalone/</em></span> directory.
						</li><li class="listitem">
							Edit the <span class="emphasis"><em>host-slave.xml</em></span> file to change the bind addresses used or override them on the command line
						</li></ol></div><section class="section" id="register_a_new_host_with_load_balancer"><div class="titlepage"><div><div><h4 class="title">8.3.4.1. Register a New Host With Load Balancer</h4></div></div></div><p>
						Let’s look first at registering the new host slave with the load balancer configuration in <span class="emphasis"><em>domain.xml</em></span>. Open this file and go to the undertow configuration in the <code class="literal">load-balancer</code> profile. Add a new <code class="literal">host</code> definition called <code class="literal">remote-host3</code> within the <code class="literal">reverse-proxy</code> XML block.
					</p><div class="formalpara"><p class="title"><strong>domain.xml reverse-proxy config</strong></p><p>
							
<pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:undertow:9.0"&gt;
  ...
  &lt;handlers&gt;
      &lt;reverse-proxy name="lb-handler"&gt;
         &lt;host name="host1" outbound-socket-binding="remote-host1" scheme="ajp" path="/" instance-id="myroute1"/&gt;
         &lt;host name="host2" outbound-socket-binding="remote-host2" scheme="ajp" path="/" instance-id="myroute2"/&gt;
         &lt;host name="remote-host3" outbound-socket-binding="remote-host3" scheme="ajp" path="/" instance-id="myroute3"/&gt;
      &lt;/reverse-proxy&gt;
  &lt;/handlers&gt;
  ...
&lt;/subsystem&gt;</pre>
						</p></div><p>
						The <code class="literal">output-socket-binding</code> is a logical name pointing to a <code class="literal">socket-binding</code> configured later in the <span class="emphasis"><em>domain.xml</em></span> file. The <code class="literal">instance-id</code> attribute must also be unique to the new host as this value is used by a cookie to enable sticky sessions when load balancing.
					</p><p>
						Next go down to the <code class="literal">load-balancer-sockets</code> <code class="literal">socket-binding-group</code> and add the <code class="literal">outbound-socket-binding</code> for <code class="literal">remote-host3</code>. This new binding needs to point to the host and port of the new host.
					</p><div class="formalpara"><p class="title"><strong>domain.xml outbound-socket-binding</strong></p><p>
							
<pre class="programlisting language-xml">&lt;socket-binding-group name="load-balancer-sockets" default-interface="public"&gt;
    ...
    &lt;outbound-socket-binding name="remote-host1"&gt;
        &lt;remote-destination host="localhost" port="8159"/&gt;
    &lt;/outbound-socket-binding&gt;
    &lt;outbound-socket-binding name="remote-host2"&gt;
        &lt;remote-destination host="localhost" port="8259"/&gt;
    &lt;/outbound-socket-binding&gt;
    &lt;outbound-socket-binding name="remote-host3"&gt;
        &lt;remote-destination host="192.168.0.5" port="8259"/&gt;
    &lt;/outbound-socket-binding&gt;
&lt;/socket-binding-group&gt;</pre>
						</p></div></section><section class="section" id="master_bind_addresses"><div class="titlepage"><div><div><h4 class="title">8.3.4.2. Master Bind Addresses</h4></div></div></div><p>
						Next thing you’ll have to do is to change the <code class="literal">public</code> and <code class="literal">management</code> bind addresses for the master host. Either edit the <span class="emphasis"><em>domain.xml</em></span> file as discussed in the <a class="link" href="#bind-address" title="7.1. Bind Addresses">Bind Addresses</a> chapter or specify these bind addresses on the command line as follows:
					</p><pre class="screen">$ domain.sh --host-config=host-master.xml -Djboss.bind.address=192.168.0.2 -Djboss.bind.address.management=192.168.0.2</pre></section><section class="section" id="host_slave_bind_addresses"><div class="titlepage"><div><div><h4 class="title">8.3.4.3. Host Slave Bind Addresses</h4></div></div></div><p>
						Next you’ll have to change the <code class="literal">public</code>, <code class="literal">management</code>, and domain controller bind addresses (<code class="literal">jboss.domain.master-address</code>). Either edit the <span class="emphasis"><em>host-slave.xml</em></span> file or specify them on the command line as follows:
					</p><pre class="screen">$ domain.sh --host-config=host-slave.xml
     -Djboss.bind.address=192.168.0.5
      -Djboss.bind.address.management=192.168.0.5
       -Djboss.domain.master.address=192.168.0.2</pre><p>
						The values of <code class="literal">jboss.bind.address</code> and <code class="literal">jboss.bind.addres.management</code> pertain to the host slave’s IP address. The value of <code class="literal">jboss.domain.master.address</code> need to be the IP address of the domain controller which is the management address of the master host.
					</p></section></section><section class="section" id="configuring_other_load_balancers"><div class="titlepage"><div><div><h3 class="title">8.3.5. Configuring Other Load Balancers</h3></div></div></div><p>
					See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#configuring_high_availability">the load balancing</a> section in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span> for information how to use other software-based load balancers.
				</p></section></section><section class="section" id="sticky-sessions"><div class="titlepage"><div><div><h2 class="title">8.4. Sticky sessions</h2></div></div></div><p>
				Typical cluster deployment consists of the load balancer (reverse proxy) and 2 or more Red Hat Single Sign-On servers on private network. For performance purposes, it may be useful if load balancer forwards all requests related to particular browser session to the same Red Hat Single Sign-On backend node.
			</p><p>
				The reason is, that Red Hat Single Sign-On is using Infinispan distributed cache under the covers for save data related to current authentication session and user session. The Infinispan distributed caches are configured with one owner by default. That means that particular session is saved just on one cluster node and the other nodes need to lookup the session remotely if they want to access it.
			</p><p>
				For example if authentication session with ID <code class="literal">123</code> is saved in the Infinispan cache on <code class="literal">node1</code>, and then <code class="literal">node2</code> needs to lookup this session, it needs to send the request to <code class="literal">node1</code> over the network to return the particular session entity.
			</p><p>
				It is beneficial if particular session entity is always available locally, which can be done with the help of sticky sessions. The workflow in the cluster environment with the public frontend load balancer and two backend Red Hat Single Sign-On nodes can be like this:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						User sends initial request to see the Red Hat Single Sign-On login screen
					</li><li class="listitem">
						This request is served by the frontend load balancer, which forwards it to some random node (eg. node1). Strictly said, the node doesn’t need to be random, but can be chosen according to some other criterias (client IP address etc). It all depends on the implementation and configuration of underlying load balancer (reverse proxy).
					</li><li class="listitem">
						Red Hat Single Sign-On creates authentication session with random ID (eg. 123) and saves it to the Infinispan cache.
					</li><li class="listitem">
						Infinispan distributed cache assigns the primary owner of the session based on the hash of session ID. See <a class="link" href="https://infinispan.org/docs/8.2.x/user_guide/user_guide.html#distribution_mode">Infinispan documentation</a> for more details around this. Let’s assume that Infinispan assigned <code class="literal">node2</code> to be the owner of this session.
					</li><li class="listitem">
						Red Hat Single Sign-On creates the cookie <code class="literal">AUTH_SESSION_ID</code> with the format like <code class="literal">&lt;session-id&gt;.&lt;owner-node-id&gt;</code> . In our example case, it will be <code class="literal">123.node2</code> .
					</li><li class="listitem">
						Response is returned to the user with the Red Hat Single Sign-On login screen and the AUTH_SESSION_ID cookie in the browser
					</li></ul></div><p>
				From this point, it is beneficial if load balancer forwards all the next requests to the <code class="literal">node2</code> as this is the node, who is owner of the authentication session with ID <code class="literal">123</code> and hence Infinispan can lookup this session locally. After authentication is finished, the authentication session is converted to user session, which will be also saved on <code class="literal">node2</code> because it has same ID <code class="literal">123</code> .
			</p><p>
				The sticky session is not mandatory for the cluster setup, however it is good for performance for the reasons mentioned above. You need to configure your loadbalancer to sticky over the <code class="literal">AUTH_SESSION_ID</code> cookie. How exactly do this is dependent on your loadbalancer.
			</p><p>
				It is recommended on the Red Hat Single Sign-On side to use the system property <code class="literal">jboss.node.name</code> during startup, with the value corresponding to the name of your route. For example, <code class="literal">-Djboss.node.name=node1</code> will use <code class="literal">node1</code> to identify the route. This route will be used by Infinispan caches and will be attached to the AUTH_SESSION_ID cookie when the node is the owner of the particular key. Here is an example of the start up command using this system property:
			</p><pre class="screen">cd $RHSSO_NODE1
./standalone.sh -c standalone-ha.xml -Djboss.socket.binding.port-offset=100 -Djboss.node.name=node1</pre><p>
				Typically in production environment the route name should use the same name as your backend host, but it is not required. You can use a different route name. For example, if you want to hide the host name of your Red Hat Single Sign-On server inside your private network.
			</p><section class="section" id="disable_adding_the_route"><div class="titlepage"><div><div><h3 class="title">8.4.1. Disable adding the route</h3></div></div></div><p>
					Some load balancers can be configured to add the route information by themselves instead of relying on the back end Red Hat Single Sign-On node. However, as described above, adding the route by the Red Hat Single Sign-On is recommended. This is because when done this way performance improves, since Red Hat Single Sign-On is aware of the entity that is the owner of particular session and can route to that node, which is not necessarily the local node.
				</p><p>
					You are permitted to disable adding route information to the AUTH_SESSION_ID cookie by Red Hat Single Sign-On, if you prefer, by adding the following into your <code class="literal">RHSSO_HOME/standalone/configuration/standalone-ha.xml</code> file in the Red Hat Single Sign-On subsystem configuration:
				</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:keycloak-server:1.1"&gt;
  ...
    &lt;spi name="stickySessionEncoder"&gt;
        &lt;provider name="infinispan" enabled="true"&gt;
            &lt;properties&gt;
                &lt;property name="shouldAttachRoute" value="false"/&gt;
            &lt;/properties&gt;
        &lt;/provider&gt;
    &lt;/spi&gt;

&lt;/subsystem&gt;</pre></section></section><section class="section" id="multicast_network_setup"><div class="titlepage"><div><div><h2 class="title">8.5. Multicast Network Setup</h2></div></div></div><p>
				Out of the box clustering support needs IP Multicast. Multicast is a network broadcast protocol. This protocol is used at boot time to discover and join the cluster. It is also used to broadcast messages for the replication and invalidation of distributed caches used by Red Hat Single Sign-On.
			</p><p>
				The clustering subsystem for Red Hat Single Sign-On runs on the JGroups stack. Out of the box, the bind addresses for clustering are bound to a private network interface with 127.0.0.1 as default IP address. You have to edit your the <span class="emphasis"><em>standalone-ha.xml</em></span> or <span class="emphasis"><em>domain.xml</em></span> sections discussed in the <a class="link" href="#bind-address" title="7.1. Bind Addresses">Bind Address</a> chapter.
			</p><div class="formalpara"><p class="title"><strong>private network config</strong></p><p>
					
<pre class="programlisting language-xml">    &lt;interfaces&gt;
        ...
        &lt;interface name="private"&gt;
            &lt;inet-address value="${jboss.bind.address.private:127.0.0.1}"/&gt;
        &lt;/interface&gt;
    &lt;/interfaces&gt;
    &lt;socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}"&gt;
        ...
        &lt;socket-binding name="jgroups-mping" interface="private" port="0" multicast-address="${jboss.default.multicast.address:230.0.0.4}" multicast-port="45700"/&gt;
        &lt;socket-binding name="jgroups-tcp" interface="private" port="7600"/&gt;
        &lt;socket-binding name="jgroups-tcp-fd" interface="private" port="57600"/&gt;
        &lt;socket-binding name="jgroups-udp" interface="private" port="55200" multicast-address="${jboss.default.multicast.address:230.0.0.4}" multicast-port="45688"/&gt;
        &lt;socket-binding name="jgroups-udp-fd" interface="private" port="54200"/&gt;
        &lt;socket-binding name="modcluster" port="0" multicast-address="224.0.1.105" multicast-port="23364"/&gt;
        ...
    &lt;/socket-binding-group&gt;</pre>
				</p></div><p>
				Things you’ll want to configure are the <code class="literal">jboss.bind.address.private</code> and <code class="literal">jboss.default.multicast.address</code> as well as the ports of the services on the clustering stack.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					It is possible to cluster Red Hat Single Sign-On without IP Multicast, but this topic is beyond the scope of this guide. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#cluster_communication_jgroups">JGroups</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
				</p></div></div></section><section class="section" id="securing_cluster_communication"><div class="titlepage"><div><div><h2 class="title">8.6. Securing Cluster Communication</h2></div></div></div><p>
				When cluster nodes are isolated on a private network it requires access to the private network to be able to join a cluster or to view communication in the cluster. In addition you can also enable authentication and encryption for cluster communication. As long as your private network is secure it is not necessary to enable authentication and encryption. Red Hat Single Sign-On does not send very sensitive information on the cluster in either case.
			</p><p>
				If you want to enable authentication and encryption for clustering communication see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.0/html/configuration_guide/configuring_high_availability#securing_cluster">Securing a Cluster</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
			</p></section><section class="section" id="clustering_db_lock"><div class="titlepage"><div><div><h2 class="title">8.7. Serialized Cluster Startup</h2></div></div></div><p>
				Red Hat Single Sign-On cluster nodes are allowed to boot concurrently. When Red Hat Single Sign-On server instance boots up it may do some database migration, importing, or first time initializations. A DB lock is used to prevent start actions from conflicting with one another when cluster nodes boot up concurrently.
			</p><p>
				By default, the maximum timeout for this lock is 900 seconds. If a node is waiting on this lock for more than the timeout it will fail to boot. Typically you won’t need to increase/decrease the default value, but just in case it’s possible to configure it in <code class="literal">standalone.xml</code>, <code class="literal">standalone-ha.xml</code>, or <code class="literal">domain.xml</code> file in your distribution. The location of this file depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>.
			</p><pre class="programlisting language-xml">&lt;spi name="dblock"&gt;
    &lt;provider name="jpa" enabled="true"&gt;
        &lt;properties&gt;
            &lt;property name="lockWaitTimeout" value="900"/&gt;
        &lt;/properties&gt;
    &lt;/provider&gt;
&lt;/spi&gt;</pre></section><section class="section" id="booting_the_cluster"><div class="titlepage"><div><div><h2 class="title">8.8. Booting the Cluster</h2></div></div></div><p>
				Booting Red Hat Single Sign-On in a cluster depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>
			</p><div class="formalpara"><p class="title"><strong>Standalone Mode</strong></p><p>
					
<pre class="screen">$ bin/standalone.sh --server-config=standalone-ha.xml</pre>
				</p></div><div class="formalpara"><p class="title"><strong>Domain Mode</strong></p><p>
					
<pre class="screen">$ bin/domain.sh --host-config=host-master.xml
$ bin/domain.sh --host-config=host-slave.xml</pre>
				</p></div><p>
				You may need to use additional parameters or system properties. For example, the parameter <code class="literal">-b</code> for the binding host or the system property <code class="literal">jboss.node.name</code> to specify the name of the route, as described in <a class="link" href="#sticky-sessions" title="8.4. Sticky sessions">Sticky Sessions </a> section.
			</p></section><section class="section" id="troubleshooting-1"><div class="titlepage"><div><div><h2 class="title">8.9. Troubleshooting</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Note that when you run a cluster, you should see message similar to this in the log of both cluster nodes:
					</p><pre class="screen">INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (Incoming-10,shared=udp)
ISPN000094: Received new cluster view: [node1/keycloak|1] (2) [node1/keycloak, node2/keycloak]</pre><p class="simpara">
						If you see just one node mentioned, it’s possible that your cluster hosts are not joined together.
					</p><p class="simpara">
						Usually it’s best practice to have your cluster nodes on private network without firewall for communication among them. Firewall could be enabled just on public access point to your network instead. If for some reason you still need to have firewall enabled on cluster nodes, you will need to open some ports. Default values are UDP port 55200 and multicast port 45688 with multicast address 230.0.0.4. Note that you may need more ports opened if you want to enable additional features like diagnostics for your JGroups stack. Red Hat Single Sign-On delegates most of the clustering work to Infinispan/JGroups. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#cluster_communication_jgroups">JGroups</a> in the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
					</p></li><li class="listitem">
						If you are interested in failover support (high availability), evictions, expiration and cache tuning, see <a class="xref" href="#cache-configuration" title="Chapter 9. Server Cache Configuration">Chapter 9, <em>Server Cache Configuration</em></a>.
					</li></ul></div></section></section><section class="chapter" id="cache-configuration"><div class="titlepage"><div><div><h1 class="title">Chapter 9. Server Cache Configuration</h1></div></div></div><p>
			Red Hat Single Sign-On has two types of caches. One type of cache sits in front of the database to decrease load on the DB and to decrease overall response times by keeping data in memory. Realm, client, role, and user metadata is kept in this type of cache. This cache is a local cache. Local caches do not use replication even if you are in the cluster with more Red Hat Single Sign-On servers. Instead, they only keep copies locally and if the entry is updated an invalidation message is sent to the rest of the cluster and the entry is evicted. There is separate replicated cache <code class="literal">work</code>, which task is to send the invalidation messages to the whole cluster about what entries should be evicted from local caches. This greatly reduces network traffic, makes things efficient, and avoids transmitting sensitive metadata over the wire.
		</p><p>
			The second type of cache handles managing user sessions, offline tokens, and keeping track of login failures so that the server can detect password phishing and other attacks. The data held in these caches is temporary, in memory only, but is possibly replicated across the cluster.
		</p><p>
			This chapter discusses some configuration options for these caches for both clustered and non-clustered deployments.
		</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				More advanced configuration of these caches can be found in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.2/html-single/configuration_guide/#infinispan">Infinispan</a> section of the <span class="emphasis"><em>JBoss EAP Configuration Guide</em></span>.
			</p></div></div><section class="section" id="eviction"><div class="titlepage"><div><div><h2 class="title">9.1. Eviction and Expiration</h2></div></div></div><p>
				There are multiple different caches configured for Red Hat Single Sign-On. There is a realm cache that holds information about secured applications, general security data, and configuration options. There is also a user cache that contains user metadata. Both caches default to a maximum of 10000 entries and use a least recently used eviction strategy. Each of them is also tied to an object revisions cache that controls eviction in a clustered setup. This cache is created implicitly and has twice the configured size. The same applies for the <code class="literal">authorization</code> cache, which holds the authorization data. The <code class="literal">keys</code> cache holds data about external keys and does not need to have dedicated revisions cache. Rather it has <code class="literal">expiration</code> explicitly declared on it, so the keys are periodically expired and forced to be periodically downloaded from external clients or identity providers.
			</p><p>
				The eviction policy and max entries for these caches can be configured in the <span class="emphasis"><em>standalone.xml</em></span>, <span class="emphasis"><em>standalone-ha.xml</em></span>, or <span class="emphasis"><em>domain.xml</em></span> depending on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>. In the configuration file, there is the part with infinispan subsystem, which looks similar to this:
			</p><pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:infinispan:8.0"&gt;
    &lt;cache-container name="keycloak"&gt;
        &lt;local-cache name="realms"&gt;
            &lt;object-memory size="10000"/&gt;
        &lt;/local-cache&gt;
        &lt;local-cache name="users"&gt;
            &lt;object-memory size="10000"/&gt;
        &lt;/local-cache&gt;
        ...
        &lt;local-cache name="keys"&gt;
            &lt;object-memory size="1000"/&gt;
            &lt;expiration max-idle="3600000"/&gt;
        &lt;/local-cache&gt;
        ...
    &lt;/cache-container&gt;</pre><p>
				To limit or expand the number of allowed entries simply add or edit the <code class="literal">object</code> element or the <code class="literal">expiration</code> element of particular cache configuration.
			</p><p>
				In addition, there are also separate caches <code class="literal">sessions</code>, <code class="literal">clientSessions</code>, <code class="literal">offlineSessions</code>, <code class="literal">offlineClientSessions</code>, <code class="literal">loginFailures</code> and <code class="literal">actionTokens</code>. These caches are distributed in cluster environment and they are unbounded in size by default. If they are bounded, it would then be possible that some sessions will be lost. Expired sessions are cleared internally by Red Hat Single Sign-On itself to avoid growing the size of these caches without limit. If you see memory issues due to a large number of sessions, you can try to:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Increase the size of cluster (more nodes in cluster means that sessions are spread more equally among nodes)
					</li><li class="listitem">
						Increase the memory for Red Hat Single Sign-On server process
					</li><li class="listitem">
						Decrease the number of owners to ensure that caches are saved in one single place. See <a class="xref" href="#replication" title="9.2. Replication and Failover">Section 9.2, “Replication and Failover”</a> for more details
					</li><li class="listitem">
						Disable l1-lifespan for distributed caches. See Infinispan documentation for more details
					</li><li class="listitem">
						Decrease session timeouts, which could be done individually for each realm in Red Hat Single Sign-On admin console. But this could affect usability for end users. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on_continuous_delivery/6/html-single/server_administration_guide/#_timeouts">Timeouts</a> for more details.
					</li></ul></div><p>
				There is an additional replicated cache, <code class="literal">work</code>, which is mostly used to send messages among cluster nodes; it is also unbounded by default. However, this cache should not cause any memory issues as entries in this cache are very short-lived.
			</p></section><section class="section" id="replication"><div class="titlepage"><div><div><h2 class="title">9.2. Replication and Failover</h2></div></div></div><p>
				There are caches like <code class="literal">sessions</code>, <code class="literal">authenticationSessions</code>, <code class="literal">offlineSessions</code>, <code class="literal">loginFailures</code> and a few others (See <a class="xref" href="#eviction" title="9.1. Eviction and Expiration">Section 9.1, “Eviction and Expiration”</a> for more details), which are configured as distributed caches when using a clustered setup. Entries are not replicated to every single node, but instead one or more nodes is chosen as an owner of that data. If a node is not the owner of a specific cache entry it queries the cluster to obtain it. What this means for failover is that if all the nodes that own a piece of data go down, that data is lost forever. By default, Red Hat Single Sign-On only specifies one owner for data. So if that one node goes down that data is lost. This usually means that users will be logged out and will have to login again.
			</p><p>
				You can change the number of nodes that replicate a piece of data by change the <code class="literal">owners</code> attribute in the <code class="literal">distributed-cache</code> declaration.
			</p><div class="formalpara"><p class="title"><strong>owners</strong></p><p>
					
<pre class="programlisting language-xml">&lt;subsystem xmlns="urn:jboss:domain:infinispan:8.0"&gt;
   &lt;cache-container name="keycloak"&gt;
       &lt;distributed-cache name="sessions" owners="2"/&gt;
...</pre>
				</p></div><p>
				Here we’ve changed it so at least two nodes will replicate one specific user login session.
			</p><div class="admonition tip"><div class="admonition_header">Tip</div><div><p>
				The number of owners recommended is really dependent on your deployment. If you do not care if users are logged out when a node goes down, then one owner is good enough and you will avoid replication.
			</p></div></div><div class="admonition tip"><div class="admonition_header">Tip</div><div><p>
				It is generally wise to configure your environment to use loadbalancer with sticky sessions. It is beneficial for performance as Red Hat Single Sign-On server, where the particular request is served, will be usually the owner of the data from the distributed cache and will therefore be able to look up the data locally. See <a class="xref" href="#sticky-sessions" title="8.4. Sticky sessions">Section 8.4, “Sticky sessions”</a> for more details.
			</p></div></div></section><section class="section" id="disabling_caching"><div class="titlepage"><div><div><h2 class="title">9.3. Disabling Caching</h2></div></div></div><p>
				To disable the realm or user cache, you must edit the <code class="literal">standalone.xml</code>, <code class="literal">standalone-ha.xml</code>, or <code class="literal">domain.xml</code> file in your distribution. The location of this file depends on your <a class="link" href="#operating-mode" title="Chapter 3. Choosing an Operating Mode">operating mode</a>. Here’s what the config looks like initially.
			</p><pre class="programlisting language-xml">    &lt;spi name="userCache"&gt;
        &lt;provider name="default" enabled="true"/&gt;
    &lt;/spi&gt;

    &lt;spi name="realmCache"&gt;
        &lt;provider name="default" enabled="true"/&gt;
    &lt;/spi&gt;</pre><p>
				To disable the cache set the <code class="literal">enabled</code> attribute to false for the cache you want to disable. You must reboot your server for this change to take effect.
			</p></section><section class="section" id="clearing_caches_at_runtime"><div class="titlepage"><div><div><h2 class="title">9.4. Clearing Caches at Runtime</h2></div></div></div><p>
				To clear the realm or user cache, go to the Red Hat Single Sign-On admin console Realm Settings→Cache Config page. On this page you can clear the realm cache, the user cache or cache of external public keys.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					The cache will be cleared for all realms!
				</p></div></div></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm140154420637184"><h1 class="legalnotice">Legal Notice</h1><div class="para">
				Copyright <span class="trademark"/>© 2019 Red Hat, Inc.
			</div><div class="para">
				Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
			</div><div class="para">
				<a class="ulink" href="http://www.apache.org/licenses/LICENSE-2.0"> http://www.apache.org/licenses/LICENSE-2.0</a>
			</div><div class="para">
				Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
			</div></div></div></div></div></div><script type="text/javascript">
                        jQuery(document).ready(function() {
                            initSwitchery();
                            jQuery('pre[class*="language-"]').each(function(i, block){hljs.highlightBlock(block);});
                        });
                    </script></body></html>